{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, copy\n",
    "from joblib import Parallel, delayed\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import tensorflow.contrib.eager as tfe\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fns_and_meta(data_pth, folders):\n",
    "    \"\"\" load the word vector model filenames\n",
    "    \"\"\"\n",
    "    models_meta = {}\n",
    "    for folder in folders:\n",
    "        for file in os.listdir(os.path.join(data_pth, \n",
    "                                            folder)):\n",
    "            model_meta = {}\n",
    "            model_meta['root'] = data_pth\n",
    "            model_meta['class'] = folder\n",
    "            model_meta['fn'] = file\n",
    "            #model_meta['name'] = file[:-4]\n",
    "            \n",
    "            if folder == 'glove':\n",
    "                dim = file[file.find('B')+2:file.find('d')]\n",
    "                model_meta['d'] = int(dim)\n",
    "            elif folder == 'w2v':\n",
    "                model_meta['d'] = 300\n",
    "            \n",
    "            models_meta[file[:-4]] = model_meta\n",
    "    \n",
    "    return models_meta\n",
    "\n",
    "def load_relsim_data(path='', fn='relsim_mean_ratings.csv'):\n",
    "\n",
    "    df = pd.read_csv(path+fn)\n",
    "    df['rel1_type'] = df['relation1'].apply(lambda x: int(x[:-1]))\n",
    "    df['rel2_type'] = df['relation2'].apply(lambda x: int(x[:-1]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def words_in_vocab(words, model):\n",
    "    \n",
    "    status = True\n",
    "    for w in words:\n",
    "        try:\n",
    "            if w not in model.vocab:\n",
    "                status = False\n",
    "        except:\n",
    "            if w not in model.keys():\n",
    "                status = False            \n",
    "    return status\n",
    "\n",
    "\n",
    "def compute_similarity(u, v, metric='e'):\n",
    "    \n",
    "    if metric in ['inner product', 'ip']:\n",
    "        return np.dot(u, v)\n",
    "    \n",
    "    elif metric in ['cosine', 'c']:\n",
    "        return 1 - cosine(u, v)\n",
    "    \n",
    "    elif metric in ['euclidean', 'e']:\n",
    "        return -euclidean(u, v)\n",
    "    \n",
    "    elif metric in ['dawn_euclidean', 'd']:\n",
    "        return 1 - euclidean(u, v)\n",
    "\n",
    "    \n",
    "def get_analogy_words(trial):\n",
    "    \n",
    "    return [trial.pair1_word1,\n",
    "            trial.pair1_word2,\n",
    "            trial.pair2_word1,\n",
    "            trial.pair2_word2]\n",
    "\n",
    "\n",
    "def get_relsim_vocab(df):\n",
    "    \n",
    "    words = []\n",
    "    words += list(df.pair1_word1.unique())\n",
    "    words += list(df.pair1_word2.unique())\n",
    "    words += list(df.pair2_word1.unique())\n",
    "    words += list(df.pair2_word2.unique())\n",
    "    \n",
    "    return list(set(words))\n",
    "\n",
    "\n",
    "def create_condensed_model_relsim(df, model):\n",
    "    \"\"\" Create a condensed model made just\n",
    "        for the relational similarity data.\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab = get_relsim_vocab(df)\n",
    "    \n",
    "    return create_condensed_model(vocab, model)\n",
    "\n",
    "\n",
    "def create_condensed_model(vocab, model):\n",
    "    \"\"\" Create a condensed model as a {word: vector} \n",
    "        dictionary object for a smaller vocabulary\n",
    "        from an input w2v gensim model.\n",
    "    \"\"\"\n",
    "    condensed_model = {}\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word in model.vocab:\n",
    "            condensed_model[word] = model[word]\n",
    "        \n",
    "    return condensed_model\n",
    "\n",
    "\n",
    "def load_model(model_fn='GoogleNews-vectors-negative300.bin',\n",
    "               data_pth = '../../../../datasets/word-vector-datasets/',\n",
    "               binary=True, load_condensed_stem=None, \n",
    "               condensed_vocab=None, save_condensed=False, \n",
    "               condensed_path=None):\n",
    "    \n",
    "    \"\"\" load word vector model w/ gensim\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'glove' in model_fn:\n",
    "        binary = False\n",
    "        data_pth += 'glove/'\n",
    "    elif 'GoogleNews' in model_fn:\n",
    "        data_pth += 'w2v/'\n",
    "        \n",
    "    if None not in [load_condensed_stem, condensed_vocab, condensed_path]:\n",
    "        c_model_fn = model_fn[:-3] + load_condensed_stem\n",
    "        c_model_path = condensed_path + c_model_fn\n",
    "        \n",
    "        if os.path.isfile(c_model_path):\n",
    "            return pickle.load(open(c_model_path, \"rb\"))\n",
    "        else:\n",
    "            model = KeyedVectors.load_word2vec_format(data_pth + model_fn, \n",
    "                                                      binary=binary)\n",
    "            c_model = create_condensed_model(condensed_vocab, model)\n",
    "            if save_condensed: pickle.dump(c_model, open(c_model_path, \"wb\"))\n",
    "            return c_model\n",
    "    else:\n",
    "        return KeyedVectors.load_word2vec_format(data_pth + model_fn, \n",
    "                                                 binary=binary)\n",
    "\n",
    "\n",
    "def makesave_or_load_condensed(models_meta):\n",
    "    \n",
    "    models = copy.deepcopy(models_meta)\n",
    "    # store all condensed models in one dict\n",
    "    for model_key in models_meta.keys():\n",
    "\n",
    "        models[model_key]['model'] = load_model(model_fn=models[model_key]['fn'],\n",
    "               data_pth=models[model_key]['root'],\n",
    "               binary=True, load_condensed_stem='relsim.condensed.p', \n",
    "               condensed_vocab=vocab, save_condensed=True, \n",
    "               condensed_path='condensed_models/')\n",
    "        \n",
    "    return models\n",
    "\n",
    "\n",
    "def get_word_vector(word, model, normalize=True):\n",
    "    \n",
    "    word_vector = model[word]\n",
    "    \n",
    "    if normalize:\n",
    "        return word_vector / norm(word_vector)\n",
    "    else:       \n",
    "        return word_vector\n",
    "\n",
    "\n",
    "def get_diff_vecs(words, model, dims=None):\n",
    "    \n",
    "    w1_vec = get_word_vector(words[0], model)\n",
    "    w2_vec = get_word_vector(words[1], model)\n",
    "    w3_vec = get_word_vector(words[2], model)\n",
    "    w4_vec = get_word_vector(words[3], model)\n",
    "    \n",
    "    diff_pair1 = w1_vec - w2_vec\n",
    "    diff_pair2 = w3_vec - w4_vec\n",
    "    \n",
    "    if dims is None:\n",
    "        return diff_pair1, diff_pair2\n",
    "    else:\n",
    "        return diff_pair1[dims], diff_pair2[dims]\n",
    "    \n",
    "\n",
    "def naive_train_val_split(df, val_percent=0.2, \n",
    "                           shuffle=True, seed=1):\n",
    "    \"\"\" Doesn't avoid shared single words\n",
    "        across train and test sets!!\n",
    "    \"\"\"\n",
    "    train_percent = 1 - val_percent\n",
    "    \n",
    "    n = df.shape[0]\n",
    "    idxs = np.arange(n)\n",
    "    np.random.seed(seed)\n",
    "    if shuffle: np.random.shuffle(idxs)\n",
    "    \n",
    "    train_idxs = idxs[:int(n*train_percent)]\n",
    "    val_idxs = idxs[int(n*train_percent):]\n",
    "    \n",
    "    return train_idxs, val_idxs\n",
    "\n",
    "\n",
    "def score_preds(df):\n",
    "    return pearsonr(df[df.in_vocab==True].mean_rating, \n",
    "                    df[df.in_vocab==True].preds)\n",
    "\n",
    "\n",
    "def get_rel_sim_preds(df, model, dims=None,\n",
    "                      metric='e'):\n",
    "    \n",
    "    preds, in_vocab = [], []\n",
    "    for r, row in df.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "        \n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "            \n",
    "            sim = compute_similarity(diff_pair1, diff_pair2,\n",
    "                                     metric=metric)\n",
    "            preds.append(sim)\n",
    "            in_vocab.append(True)\n",
    "        else:\n",
    "            preds.append(999)\n",
    "            in_vocab.append(False)\n",
    "        \n",
    "    df['preds'] = preds\n",
    "    df['in_vocab'] = in_vocab\n",
    "    return df\n",
    "\n",
    "def search_for_best_axes(df, model, epsilon=0, verbose=0):\n",
    "    \"\"\" Find the subset of dimensions (axis-aligned subspace)\n",
    "        giving the best fit to human data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_feats = model['dog'].size\n",
    "    feat_idx_keep = np.arange(n_feats)\n",
    "    \n",
    "    df_pred = get_rel_sim_preds(df, model)\n",
    "    base_score = score_preds(df_pred)[0]\n",
    "    best_score = base_score\n",
    "    if verbose > 0:\n",
    "        print('Base Score : %.4f, Features: %i' % (best_score, n_feats))\n",
    "    \n",
    "    for feat_idx in np.arange(n_feats):\n",
    "        \n",
    "        curr_feat_set_proposal = feat_idx_keep[feat_idx_keep!=feat_idx]\n",
    "\n",
    "        df_pred = get_rel_sim_preds(df, model, dims=curr_feat_set_proposal)\n",
    "        curr_score = score_preds(df_pred)[0]\n",
    "        \n",
    "        if (curr_score > best_score) and (curr_score-best_score > epsilon):\n",
    "            best_score = curr_score\n",
    "            feat_idx_keep = curr_feat_set_proposal\n",
    "            if verbose > 1:\n",
    "                print('-- New Best: %.4f, Features: %i' % (best_score, feat_idx_keep.size))\n",
    "                \n",
    "    if verbose > 0:                \n",
    "        print('Final Score: %.4f, Features: %i' % (best_score, feat_idx_keep.size))\n",
    "            \n",
    "    return feat_idx_keep, base_score, best_score\n",
    "\n",
    "# def apply_func_to_all_models(models, func, subset=None):\n",
    "    \n",
    "#     if subset is not None: \n",
    "#         model_list = models.keys()\n",
    "#     else:\n",
    "#         model_list = subset\n",
    "    \n",
    "#     results = {}\n",
    "#     for model_key in model_list:\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load human relational similarity data\n",
    "df_rel_sim = load_relsim_data()\n",
    "\n",
    "# get the vocab for the dataset\n",
    "vocab = get_relsim_vocab(df_rel_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to find vector space models\n",
    "data_pth = '../../../../datasets/word-vector-datasets/'\n",
    "folders = ['glove','w2v']\n",
    "\n",
    "# load meta for all models\n",
    "models_meta = get_fns_and_meta(data_pth, folders)\n",
    "\n",
    "# store all condensed models in one dict\n",
    "models = makesave_or_load_condensed(models_meta)\n",
    "\n",
    "# quick pointers to a few important models\n",
    "w2v_gnews = models['GoogleNews-vectors-negative300']['model']\n",
    "glove = models['glove.840B.300d']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300 (0.2612749669349393, 3.2947565200076315e-97)\n",
      "glove.840B.300d (0.24200000103895664, 3.0018737071108936e-83)\n"
     ]
    }
   ],
   "source": [
    "# model_list = models.keys()\n",
    "model_list = ['GoogleNews-vectors-negative300',\n",
    "              'glove.840B.300d']\n",
    "\n",
    "# basic analysis\n",
    "for model_key in model_list:\n",
    "    model = models[model_key]['model']\n",
    "    df_rel_sim = get_rel_sim_preds(df_rel_sim, model)\n",
    "    print(model_key, \n",
    "          score_preds(df_rel_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300\n",
      "Base Score : 0.2613, Features: 300\n",
      "Final Score: 0.3426, Features: 157\n",
      "\n",
      "glove.840B.300d\n",
      "Base Score : 0.2420, Features: 300\n",
      "Final Score: 0.3126, Features: 154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "for m, model_key in enumerate(model_list):\n",
    "    model = models[model_key]['model']\n",
    "    print(model_key)\n",
    "    search_for_best_axes(df_rel_sim, model, epsilon=0.0001, verbose=1)\n",
    "    if (m+1) < len(model_list): print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "n_splits = 10\n",
    "epsilon = 0.0001\n",
    "\n",
    "all_base_scores = []\n",
    "all_best_scores = []\n",
    "\n",
    "train_base_scores = []\n",
    "train_best_scores = []\n",
    "\n",
    "val_base_scores = []\n",
    "val_best_scores = []\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "\n",
    "    feats_all_data, all_base_score, all_best_score = \\\n",
    "        search_for_best_axes(df_exp, model, verbose=1, epsilon=epsilon)\n",
    "    all_base_scores.append(all_base_score)\n",
    "    all_best_scores.append(all_best_score)\n",
    "    print('')\n",
    "    \n",
    "    avg_train_base_scores = []\n",
    "    avg_train_best_scores = []\n",
    "    avg_val_base_scores = []\n",
    "    avg_val_best_scores = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        train_idxs, val_idxs = naive_train_val_split(df_exp, \n",
    "                                                      val_percent=0.2, \n",
    "                                                      shuffle=True)\n",
    "\n",
    "    #     print('Type', rel_type, ' - Training Score', \n",
    "    #           df_exp.iloc[train_idxs].shape[0])\n",
    "\n",
    "        feats_train, train_base_score, train_best_score = \\\n",
    "            search_for_best_axes(df_exp.iloc[train_idxs].copy(), \n",
    "                                 model, verbose=0, epsilon=epsilon)\n",
    "        \n",
    "        df_val_base = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model)\n",
    "        df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model, dims=feats_train)\n",
    "        print(score_preds(df_val)[0])\n",
    "        \n",
    "        avg_train_base_scores.append(train_base_score)\n",
    "        avg_train_best_scores.append(train_best_score)\n",
    "        avg_val_base_scores.append(score_preds(df_val_base)[0])\n",
    "        avg_val_best_scores.append(score_preds(df_val)[0])\n",
    "        \n",
    "    print('mean val', np.mean(avg_val_best_scores))\n",
    "    \n",
    "    train_base_scores.append(np.mean(avg_train_base_scores))\n",
    "    train_best_scores.append(np.mean(avg_train_best_scores))\n",
    "    val_base_scores.append(np.mean(avg_val_base_scores))\n",
    "    val_best_scores.append(np.mean(avg_val_best_scores))\n",
    "#     print('')\n",
    "    \n",
    "#     df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model, dims=feats_train)\n",
    "\n",
    "#     print('Type', rel_type, ' - Validation Score', \n",
    "#           df_exp.iloc[val_idxs].shape[0])\n",
    "#     print('%.4f' % score_preds(df_val)[0])\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOBLIB TEST!!! ###\n",
    "\n",
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "condensed_model = create_condensed_model(df_rel_sim, model)\n",
    "\n",
    "n_splits = 50\n",
    "epsilon = 0.0001\n",
    "\n",
    "all_base_scores = []\n",
    "all_best_scores = []\n",
    "\n",
    "train_base_scores = []\n",
    "train_best_scores = []\n",
    "\n",
    "val_base_scores = []\n",
    "val_best_scores = []\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "\n",
    "    feats_all_data, all_base_score, all_best_score = \\\n",
    "        search_for_best_axes(df_exp, model, verbose=0, epsilon=epsilon)\n",
    "    all_base_scores.append(all_base_score)\n",
    "    all_best_scores.append(all_best_score)\n",
    "#     print('')\n",
    "    \n",
    "    avg_train_base_scores = []\n",
    "    avg_train_best_scores = []\n",
    "    avg_val_base_scores = []\n",
    "    avg_val_best_scores = []\n",
    "    \n",
    "    def run_split(seed, df_exp):\n",
    "        train_idxs, val_idxs = naive_train_val_split(df_exp, \n",
    "                                                      val_percent=0.2,\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=seed)\n",
    "\n",
    "        feats_train, train_base_score, train_best_score = \\\n",
    "            search_for_best_axes(df_exp.iloc[train_idxs].copy(), \n",
    "                                 condensed_model, verbose=0, epsilon=epsilon)\n",
    "        \n",
    "        df_val_base = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), condensed_model)\n",
    "        val_base_score = score_preds(df_val_base)[0]\n",
    "        \n",
    "        df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), condensed_model, dims=feats_train)\n",
    "        val_best_score = score_preds(df_val)[0]\n",
    "        \n",
    "        return train_base_score, train_best_score, val_base_score, val_best_score\n",
    "    \n",
    "    results = Parallel(n_jobs=n_splits)(delayed(run_split)(i, df_exp) for i in range(n_splits))\n",
    "    for result in results: print(result)\n",
    "    \n",
    "    for result in results:        \n",
    "        avg_train_base_scores.append(result[0])\n",
    "        avg_train_best_scores.append(result[1])\n",
    "        avg_val_base_scores.append(result[2])\n",
    "        avg_val_best_scores.append(result[3])\n",
    "        \n",
    "    print('mean val', np.mean(avg_val_best_scores))\n",
    "    \n",
    "    train_base_scores.append(np.mean(avg_train_base_scores))\n",
    "    train_best_scores.append(np.mean(avg_train_best_scores))\n",
    "    val_base_scores.append(np.mean(avg_val_base_scores))\n",
    "    val_best_scores.append(np.mean(avg_val_best_scores))\n",
    "\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 1 epsilon test\n",
    "# 121 0       0.5298 0.4289\n",
    "# 121 0.00001 0.5298 0.4127\n",
    "# 127 0.0001  0.5230 0.4552\n",
    "# 204 0.001   0.4023 0.3364\n",
    "# 300 0.01    0.1511 NA\n",
    "# 300 0.1     0.1511 NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "    df_exp = get_rel_sim_preds(df_exp, model, metric='e')\n",
    "\n",
    "    print(score_preds(df_exp)[0])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = all_base_scores\n",
    "bars2 = all_best_scores\n",
    "bars3 = val_best_scores\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='black', width=barWidth, edgecolor='white', \n",
    "        label='Original GloVe')\n",
    "plt.axhline(y=np.mean(bars1), color='black', linestyle='--')\n",
    "plt.bar(r2, bars2, color='#2d7f5e', width=barWidth, edgecolor='white', \n",
    "        label='Best Subspace (All Data)')\n",
    "plt.axhline(y=np.mean(bars2), color='#2d7f5e', linestyle='--')\n",
    "plt.bar(r3, bars3, color='purple', width=barWidth, edgecolor='white', \n",
    "        label='Best Subspace (Mean 10x Validation)')\n",
    "plt.axhline(y=np.mean(bars3), color='purple', linestyle='--')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "# plt.xlabel('group', fontweight='bold')\n",
    "plt.ylabel('Pearson $r$', fontweight='bold')\n",
    "plt.xlabel('Relation Type', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], range(1, 11))\n",
    "\n",
    "plt.ylim([0,1])\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_params = (df_rel_sim.rel1_type==2) & (df_rel_sim.rel2_type==2)\n",
    "\n",
    "df_rel_sim[exp_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# fig, ax = plt.subplots(2, 5)\n",
    "# ax = ax.flatten()\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    plt.figure()\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    result = search_for_best_axes(df_exp, model, \n",
    "                                  epsilon=0.0001, verbose=0)\n",
    "    good_feats = result[0]\n",
    "    \n",
    "    for r, row in df_exp.iterrows():\n",
    "\n",
    "        words = get_analogy_words(row)\n",
    "\n",
    "        if words_in_vocab(words, model):\n",
    "\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model)\n",
    "\n",
    "            sim = compute_similarity(diff_pair1[good_feats], \n",
    "                                     diff_pair2[good_feats],\n",
    "                                     metric='e')\n",
    "        plt.scatter(row.mean_rating, -sim, \n",
    "                    s=10, color='blue', alpha=0.5)\n",
    "#         ax[rel_type-1].scatter(row.mean_rating, -sim, \n",
    "#                     s=10, color='blue', alpha=0.5)\n",
    "    print(rel_type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relation1</th>\n",
       "      <th>relation2</th>\n",
       "      <th>comparison_type</th>\n",
       "      <th>pair1_word1</th>\n",
       "      <th>pair1_word2</th>\n",
       "      <th>pair2_word1</th>\n",
       "      <th>pair2_word2</th>\n",
       "      <th>mean_rating</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>rel1_type</th>\n",
       "      <th>rel2_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>5a</td>\n",
       "      <td>5a</td>\n",
       "      <td>within-subtype</td>\n",
       "      <td>cherry</td>\n",
       "      <td>red</td>\n",
       "      <td>clay</td>\n",
       "      <td>malleable</td>\n",
       "      <td>4.636364</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>8a</td>\n",
       "      <td>8a</td>\n",
       "      <td>within-subtype</td>\n",
       "      <td>stimulus</td>\n",
       "      <td>response</td>\n",
       "      <td>sweat</td>\n",
       "      <td>run</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4123</th>\n",
       "      <td>1a</td>\n",
       "      <td>1a</td>\n",
       "      <td>within-subtype</td>\n",
       "      <td>car</td>\n",
       "      <td>mustang</td>\n",
       "      <td>politician</td>\n",
       "      <td>senator</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>8b</td>\n",
       "      <td>8a</td>\n",
       "      <td>between-subtype</td>\n",
       "      <td>coldness</td>\n",
       "      <td>shiver</td>\n",
       "      <td>eating</td>\n",
       "      <td>fullness</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>5a</td>\n",
       "      <td>5a</td>\n",
       "      <td>within-subtype</td>\n",
       "      <td>intellectual</td>\n",
       "      <td>professor</td>\n",
       "      <td>murderer</td>\n",
       "      <td>evil</td>\n",
       "      <td>4.090909</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     relation1 relation2  comparison_type   pair1_word1 pair1_word2  \\\n",
       "3524        5a        5a   within-subtype        cherry         red   \n",
       "2629        8a        8a   within-subtype      stimulus    response   \n",
       "4123        1a        1a   within-subtype           car     mustang   \n",
       "5529        8b        8a  between-subtype      coldness      shiver   \n",
       "2766        5a        5a   within-subtype  intellectual   professor   \n",
       "\n",
       "     pair2_word1 pair2_word2  mean_rating  num_ratings  rel1_type  rel2_type  \n",
       "3524        clay   malleable     4.636364           11          5          5  \n",
       "2629       sweat         run     4.000000           11          8          8  \n",
       "4123  politician     senator     6.000000           11          1          1  \n",
       "5529      eating    fullness     5.400000           10          8          8  \n",
       "2766    murderer        evil     4.090909           11          5          5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_rel_sim.copy()\n",
    "\n",
    "# train_idxs, val_idxs = naive_train_val_split(df)\n",
    "\n",
    "# train_raw = df.iloc[train_idxs].copy()\n",
    "# val_raw = df.iloc[val_idxs].copy()\n",
    "\n",
    "\n",
    "\n",
    "# val_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comparison_type_between-subtype</th>\n",
       "      <th>comparison_type_between-type</th>\n",
       "      <th>comparison_type_within-subtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6164</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6167</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6169</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6194 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comparison_type_between-subtype  comparison_type_between-type  \\\n",
       "0                                   0                             0   \n",
       "1                                   0                             0   \n",
       "2                                   0                             0   \n",
       "3                                   0                             0   \n",
       "4                                   0                             0   \n",
       "5                                   0                             0   \n",
       "6                                   0                             0   \n",
       "7                                   0                             1   \n",
       "8                                   0                             1   \n",
       "9                                   0                             0   \n",
       "10                                  0                             0   \n",
       "11                                  0                             0   \n",
       "12                                  0                             0   \n",
       "13                                  0                             0   \n",
       "14                                  0                             0   \n",
       "15                                  0                             0   \n",
       "16                                  0                             0   \n",
       "17                                  0                             0   \n",
       "18                                  1                             0   \n",
       "19                                  1                             0   \n",
       "20                                  1                             0   \n",
       "21                                  0                             0   \n",
       "22                                  0                             0   \n",
       "23                                  1                             0   \n",
       "24                                  0                             1   \n",
       "25                                  0                             0   \n",
       "26                                  0                             0   \n",
       "27                                  0                             1   \n",
       "28                                  0                             0   \n",
       "29                                  0                             0   \n",
       "...                               ...                           ...   \n",
       "6164                                1                             0   \n",
       "6165                                0                             0   \n",
       "6166                                0                             0   \n",
       "6167                                0                             1   \n",
       "6168                                0                             0   \n",
       "6169                                0                             0   \n",
       "6170                                1                             0   \n",
       "6171                                0                             1   \n",
       "6172                                0                             1   \n",
       "6173                                0                             0   \n",
       "6174                                0                             0   \n",
       "6175                                0                             0   \n",
       "6176                                1                             0   \n",
       "6177                                0                             1   \n",
       "6178                                0                             0   \n",
       "6179                                0                             0   \n",
       "6180                                0                             1   \n",
       "6181                                1                             0   \n",
       "6182                                0                             0   \n",
       "6183                                0                             0   \n",
       "6184                                0                             0   \n",
       "6185                                0                             0   \n",
       "6186                                0                             1   \n",
       "6187                                0                             1   \n",
       "6188                                0                             1   \n",
       "6189                                1                             0   \n",
       "6190                                0                             1   \n",
       "6191                                0                             1   \n",
       "6192                                0                             0   \n",
       "6193                                0                             0   \n",
       "\n",
       "      comparison_type_within-subtype  \n",
       "0                                  1  \n",
       "1                                  1  \n",
       "2                                  1  \n",
       "3                                  1  \n",
       "4                                  1  \n",
       "5                                  1  \n",
       "6                                  1  \n",
       "7                                  0  \n",
       "8                                  0  \n",
       "9                                  1  \n",
       "10                                 1  \n",
       "11                                 1  \n",
       "12                                 1  \n",
       "13                                 1  \n",
       "14                                 1  \n",
       "15                                 1  \n",
       "16                                 1  \n",
       "17                                 1  \n",
       "18                                 0  \n",
       "19                                 0  \n",
       "20                                 0  \n",
       "21                                 1  \n",
       "22                                 1  \n",
       "23                                 0  \n",
       "24                                 0  \n",
       "25                                 1  \n",
       "26                                 1  \n",
       "27                                 0  \n",
       "28                                 1  \n",
       "29                                 1  \n",
       "...                              ...  \n",
       "6164                               0  \n",
       "6165                               1  \n",
       "6166                               1  \n",
       "6167                               0  \n",
       "6168                               1  \n",
       "6169                               1  \n",
       "6170                               0  \n",
       "6171                               0  \n",
       "6172                               0  \n",
       "6173                               1  \n",
       "6174                               1  \n",
       "6175                               1  \n",
       "6176                               0  \n",
       "6177                               0  \n",
       "6178                               1  \n",
       "6179                               1  \n",
       "6180                               0  \n",
       "6181                               0  \n",
       "6182                               1  \n",
       "6183                               1  \n",
       "6184                               1  \n",
       "6185                               1  \n",
       "6186                               0  \n",
       "6187                               0  \n",
       "6188                               0  \n",
       "6189                               0  \n",
       "6190                               0  \n",
       "6191                               0  \n",
       "6192                               1  \n",
       "6193                               1  \n",
       "\n",
       "[6194 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df_rel_sim, columns=['comparison_type'])[['comparison_type_between-subtype', \n",
    "                                                        'comparison_type_between-type',\n",
    "                                                        'comparison_type_within-subtype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4220, 300)\n",
      "(1055, 300)\n",
      "(4220, 300)\n",
      "(1055, 300)\n",
      "(4220,)\n",
      "(1055,)\n"
     ]
    }
   ],
   "source": [
    "# df_exp = df_rel_sim.copy() # all data\n",
    "df_exp = df_rel_sim[df_rel_sim.comparison_type!='between-type'].copy()\n",
    "\n",
    "train_idxs, val_idxs = naive_train_val_split(df_exp, seed=3)\n",
    "\n",
    "def build_data_for_tuning(df, model, train_idxs, val_idxs, dims=None):\n",
    "    \n",
    "    train_raw = df.iloc[train_idxs].copy()\n",
    "    val_raw = df.iloc[val_idxs].copy()\n",
    "    \n",
    "    U_train, U_val = [], []\n",
    "    V_train, V_val = [], []\n",
    "    y_train, y_val = [], []\n",
    "#     type_train = [], type_val = [], []\n",
    "    \n",
    "    for r, row in train_raw.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "        \n",
    "        U_train.append(diff_pair1)\n",
    "        V_train.append(diff_pair2)\n",
    "        y_train.append(row.mean_rating)\n",
    "        \n",
    "    for r, row in val_raw.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "            \n",
    "        U_val.append(diff_pair1)\n",
    "        V_val.append(diff_pair2)\n",
    "        y_val.append(row.mean_rating)\n",
    "        \n",
    "    return [np.array(x) for x in [U_train, U_val, V_train, V_val, y_train, y_val]]\n",
    "\n",
    "# create dataset\n",
    "U_train, U_val, V_train, V_val, y_train, y_val = \\\n",
    "    build_data_for_tuning(df_exp,\n",
    "                          w2v_gnews, train_idxs, val_idxs)\n",
    "\n",
    "# check shapes\n",
    "for _ in [U_train, U_val, V_train, V_val, y_train, y_val]:\n",
    "    print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3612125067202853\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for u, v in zip(U_val, V_val):\n",
    "    pred = compute_similarity(u, v, metric='e')\n",
    "    preds.append(pred)\n",
    "    \n",
    "print(np.corrcoef(preds, y_val)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.15909395023178471\n",
      "Val  : 0.12341639451952253\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 2s 390us/step - loss: 24.4612 - val_loss: 25.3279\n",
      "Train: 0.2911924191502079\n",
      "Val  : 0.280953168123332\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 83us/step - loss: 24.0944 - val_loss: 24.7674\n",
      "Train: 0.2932714493549004\n",
      "Val  : 0.2797243793124052\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 23.3769 - val_loss: 23.8962\n",
      "Train: 0.29461579493467493\n",
      "Val  : 0.2795435432434388\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 85us/step - loss: 22.3852 - val_loss: 22.8852\n",
      "Train: 0.2962890397991324\n",
      "Val  : 0.28010212808337487\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 21.3705 - val_loss: 21.9749\n",
      "Train: 0.29908567304032907\n",
      "Val  : 0.2810477437798998\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 86us/step - loss: 20.4598 - val_loss: 21.2167\n",
      "Train: 0.3030104514865415\n",
      "Val  : 0.2820101248012115\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 19.6293 - val_loss: 20.5277\n",
      "Train: 0.30615378384530817\n",
      "Val  : 0.28182646107574294\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 18.8244 - val_loss: 19.8622\n",
      "Train: 0.30736781164826654\n",
      "Val  : 0.2799593002550552\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 83us/step - loss: 18.0353 - val_loss: 19.2192\n",
      "Train: 0.30672959932867194\n",
      "Val  : 0.2769835192043342\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 17.2582 - val_loss: 18.5944\n",
      "Train: 0.3050048284220991\n",
      "Val  : 0.2736356661171845\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 16.5036 - val_loss: 17.9948\n",
      "Train: 0.3023910899008607\n",
      "Val  : 0.26984771818466524\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 81us/step - loss: 15.7800 - val_loss: 17.4256\n",
      "Train: 0.29950118768952283\n",
      "Val  : 0.26606270026003837\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 15.0869 - val_loss: 16.8789\n",
      "Train: 0.29678172129713465\n",
      "Val  : 0.2626225231351804\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 85us/step - loss: 14.4202 - val_loss: 16.3623\n",
      "Train: 0.29379605214128285\n",
      "Val  : 0.2589593246532372\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 13.7885 - val_loss: 15.8723\n",
      "Train: 0.2918123488544459\n",
      "Val  : 0.25634306059340994\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 82us/step - loss: 13.1869 - val_loss: 15.4093\n",
      "Train: 0.29056200421483686\n",
      "Val  : 0.2542515531259253\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 84us/step - loss: 12.6149 - val_loss: 14.9726\n",
      "Train: 0.289360528329063\n",
      "Val  : 0.25204901736556007\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 87us/step - loss: 12.0718 - val_loss: 14.5651\n",
      "Train: 0.2892595840690069\n",
      "Val  : 0.25042496517261575\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 11.5590 - val_loss: 14.1751\n",
      "Train: 0.28883918658229646\n",
      "Val  : 0.24843607498033596\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 11.0663 - val_loss: 13.8094\n",
      "Train: 0.2905792375173439\n",
      "Val  : 0.2482325484768011\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 83us/step - loss: 10.6041 - val_loss: 13.4648\n",
      "Train: 0.2915698127341165\n",
      "Val  : 0.24703988944038702\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 10.1613 - val_loss: 13.1401\n",
      "Train: 0.2940126150472596\n",
      "Val  : 0.2471772152122086\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 85us/step - loss: 9.7441 - val_loss: 12.8381\n",
      "Train: 0.29604861288446543\n",
      "Val  : 0.2464874858523428\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 9.3476 - val_loss: 12.5526\n",
      "Train: 0.2993018433023168\n",
      "Val  : 0.24668909715641443\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 86us/step - loss: 8.9697 - val_loss: 12.2850\n",
      "Train: 0.30311112305181964\n",
      "Val  : 0.24715192409214712\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 8.6099 - val_loss: 12.0321\n",
      "Train: 0.3075703676586605\n",
      "Val  : 0.24786014444348325\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 8.2655 - val_loss: 11.7956\n",
      "Train: 0.31205902522368684\n",
      "Val  : 0.24831547272165266\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 7.9394 - val_loss: 11.5723\n",
      "Train: 0.31695164673136106\n",
      "Val  : 0.24877509511797663\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 7.6269 - val_loss: 11.3650\n",
      "Train: 0.3230094524123286\n",
      "Val  : 0.2502798178817928\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 87us/step - loss: 7.3293 - val_loss: 11.1711\n",
      "Train: 0.3279078225580073\n",
      "Val  : 0.25016175721617134\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 7.0446 - val_loss: 10.9874\n",
      "Train: 0.33346415267197205\n",
      "Val  : 0.2506185782883143\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 87us/step - loss: 6.7736 - val_loss: 10.8161\n",
      "Train: 0.34031399120636036\n",
      "Val  : 0.25199247560967886\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 88us/step - loss: 6.5136 - val_loss: 10.6542\n",
      "Train: 0.3471080312251536\n",
      "Val  : 0.25313234814514113\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 6.2649 - val_loss: 10.5009\n",
      "Train: 0.35362216070611246\n",
      "Val  : 0.2536446705103714\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 6.0248 - val_loss: 10.3566\n",
      "Train: 0.3607185260756988\n",
      "Val  : 0.25458857652692396\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 5.7965 - val_loss: 10.2232\n",
      "Train: 0.36738699116309603\n",
      "Val  : 0.25488346975319676\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 5.5771 - val_loss: 10.0956\n",
      "Train: 0.3748752594416959\n",
      "Val  : 0.25587726934762317\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 5.3670 - val_loss: 9.9751\n",
      "Train: 0.3819769260845458\n",
      "Val  : 0.2563174938697478\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "2240/4220 [==============>...............] - ETA: 0s - loss: 4.8948"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-e8475f4931f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     tuner.fit([U_train, V_train], y_train, \n\u001b[1;32m     38\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mU_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0meval_tuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import concatenate, multiply, dot\n",
    "from keras.models import Model\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='linear')(diff_vecs)\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(60):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: -0.005118875210539643\n",
      "Val  : 0.04605324904128041\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 2s 312us/step - loss: 22.2639 - val_loss: 21.9248\n",
      "Train: 0.35204706319832485\n",
      "Val  : 0.29338229696939916\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 87us/step - loss: 22.0161 - val_loss: 21.7872\n",
      "Train: 0.3555073309537335\n",
      "Val  : 0.2941301028985686\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 21.7777 - val_loss: 21.6516\n",
      "Train: 0.3560480131314369\n",
      "Val  : 0.29370307846711013\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 21.5440 - val_loss: 21.5211\n",
      "Train: 0.3568327417653905\n",
      "Val  : 0.29382202626293924\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 21.3171 - val_loss: 21.3938\n",
      "Train: 0.35728863240589476\n",
      "Val  : 0.2938259803097887\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 21.0957 - val_loss: 21.2696\n",
      "Train: 0.35784704811870083\n",
      "Val  : 0.2939979082262203\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 20.8792 - val_loss: 21.1493\n",
      "Train: 0.3583934695283921\n",
      "Val  : 0.29415302674455257\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 20.6670 - val_loss: 21.0318\n",
      "Train: 0.3589378683945502\n",
      "Val  : 0.294291323327725\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 20.4604 - val_loss: 20.9175\n",
      "Train: 0.3594389440980731\n",
      "Val  : 0.2944854707683996\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 20.2584 - val_loss: 20.8060\n",
      "Train: 0.36001813011720235\n",
      "Val  : 0.2947566231040115\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 20.0603 - val_loss: 20.6971\n",
      "Train: 0.36062022595269005\n",
      "Val  : 0.29498842397802816\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 19.8671 - val_loss: 20.5918\n",
      "Train: 0.36119787746938087\n",
      "Val  : 0.29521716901695905\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 19.6778 - val_loss: 20.4888\n",
      "Train: 0.36176289028391095\n",
      "Val  : 0.29540703421275966\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 91us/step - loss: 19.4936 - val_loss: 20.3886\n",
      "Train: 0.36231002605614077\n",
      "Val  : 0.29560664542847953\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 19.3129 - val_loss: 20.2912\n",
      "Train: 0.36289263492422935\n",
      "Val  : 0.2957979773623405\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 88us/step - loss: 19.1369 - val_loss: 20.1965\n",
      "Train: 0.3635087393704046\n",
      "Val  : 0.2960303518604919\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 18.9643 - val_loss: 20.1041\n",
      "Train: 0.364137996309548\n",
      "Val  : 0.29629316478943174\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 18.7950 - val_loss: 20.0141\n",
      "Train: 0.36475252371115985\n",
      "Val  : 0.29649834536073044\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 18.6301 - val_loss: 19.9269\n",
      "Train: 0.36539544132234664\n",
      "Val  : 0.2967757463864876\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 18.4690 - val_loss: 19.8419\n",
      "Train: 0.3660629835108289\n",
      "Val  : 0.29703812139909574\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 18.3113 - val_loss: 19.7593\n",
      "Train: 0.3666993800948695\n",
      "Val  : 0.29724537716588506\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 18.1564 - val_loss: 19.6790\n",
      "Train: 0.36735562579057535\n",
      "Val  : 0.29748109363463626\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 18.0053 - val_loss: 19.6007\n",
      "Train: 0.36802836975541875\n",
      "Val  : 0.29774826298516416\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 86us/step - loss: 17.8568 - val_loss: 19.5245\n",
      "Train: 0.36868622186336214\n",
      "Val  : 0.2979963397837954\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 85us/step - loss: 17.7113 - val_loss: 19.4498\n",
      "Train: 0.3693687874002371\n",
      "Val  : 0.2982660993274292\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 17.5688 - val_loss: 19.3771\n",
      "Train: 0.3700522223712588\n",
      "Val  : 0.2985164333515218\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 17.4292 - val_loss: 19.3067\n",
      "Train: 0.3707534768267464\n",
      "Val  : 0.29875234131649764\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 17.2920 - val_loss: 19.2377\n",
      "Train: 0.3714529537803576\n",
      "Val  : 0.29896356903858634\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 17.1572 - val_loss: 19.1708\n",
      "Train: 0.37215672698310076\n",
      "Val  : 0.29918836877946176\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 17.0252 - val_loss: 19.1051\n",
      "Train: 0.3728851364096458\n",
      "Val  : 0.2994571307770878\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 16.8954 - val_loss: 19.0412\n",
      "Train: 0.3736157747080049\n",
      "Val  : 0.2996977804937889\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 16.7679 - val_loss: 18.9789\n",
      "Train: 0.3743253667299196\n",
      "Val  : 0.2999074502695924\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 16.6426 - val_loss: 18.9183\n",
      "Train: 0.3750544554660164\n",
      "Val  : 0.30014269931327703\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 16.5194 - val_loss: 18.8589\n",
      "Train: 0.37579510279286754\n",
      "Val  : 0.30040536029725906\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 16.3984 - val_loss: 18.8009\n",
      "Train: 0.37651421323566164\n",
      "Val  : 0.30062480067212477\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 16.2789 - val_loss: 18.7440\n",
      "Train: 0.3772555066240841\n",
      "Val  : 0.30086912515163394\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 83us/step - loss: 16.1618 - val_loss: 18.6884\n",
      "Train: 0.3779880165878144\n",
      "Val  : 0.30108834577909577\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 16.0461 - val_loss: 18.6337\n",
      "Train: 0.3787283771216275\n",
      "Val  : 0.30132223929621677\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 15.9322 - val_loss: 18.5807\n",
      "Train: 0.37946193274822954\n",
      "Val  : 0.3015488402048284\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 15.8203 - val_loss: 18.5285\n",
      "Train: 0.3802178865742299\n",
      "Val  : 0.3017961787647287\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 15.7096 - val_loss: 18.4774\n",
      "Train: 0.3809615939710791\n",
      "Val  : 0.3020155683697011\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 15.6004 - val_loss: 18.4273\n",
      "Train: 0.38171461154920033\n",
      "Val  : 0.3022663187735497\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 15.4927 - val_loss: 18.3783\n",
      "Train: 0.3824583446304527\n",
      "Val  : 0.3024711473599949\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 15.3869 - val_loss: 18.3306\n",
      "Train: 0.38320164915994187\n",
      "Val  : 0.3026864324130896\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 15.2826 - val_loss: 18.2835\n",
      "Train: 0.3839416628027745\n",
      "Val  : 0.30289763235004613\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 15.1792 - val_loss: 18.2372\n",
      "Train: 0.38468817789752613\n",
      "Val  : 0.30309989658229636\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 15.0771 - val_loss: 18.1918\n",
      "Train: 0.38543110537033115\n",
      "Val  : 0.30330749122342127\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 14.9764 - val_loss: 18.1471\n",
      "Train: 0.3861710545647957\n",
      "Val  : 0.30351675892706675\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 14.8769 - val_loss: 18.1036\n",
      "Train: 0.38690315130114616\n",
      "Val  : 0.3037153179128557\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 14.7787 - val_loss: 18.0606\n",
      "Train: 0.3876443109432782\n",
      "Val  : 0.3039231673639436\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 14.6814 - val_loss: 18.0183\n",
      "Train: 0.38837381016334055\n",
      "Val  : 0.30411709999456443\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 14.5855 - val_loss: 17.9770\n",
      "Train: 0.38910328618949\n",
      "Val  : 0.3043027503861354\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 14.4907 - val_loss: 17.9361\n",
      "Train: 0.3898305057823249\n",
      "Val  : 0.3044750335876582\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 14.3967 - val_loss: 17.8959\n",
      "Train: 0.39055620924043616\n",
      "Val  : 0.3046644782716823\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 14.3036 - val_loss: 17.8564\n",
      "Train: 0.3912831357497842\n",
      "Val  : 0.3048422619611254\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 14.2118 - val_loss: 17.8176\n",
      "Train: 0.39199795162503925\n",
      "Val  : 0.305012100149695\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 14.1209 - val_loss: 17.7795\n",
      "Train: 0.39272928344696906\n",
      "Val  : 0.30519386672450716\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 14.0308 - val_loss: 17.7417\n",
      "Train: 0.3934407688073413\n",
      "Val  : 0.30536007752489563\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 13.9417 - val_loss: 17.7048\n",
      "Train: 0.3941611150545716\n",
      "Val  : 0.3055142628770401\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 13.8534 - val_loss: 17.6682\n",
      "Train: 0.39486502811328217\n",
      "Val  : 0.30568032710994975\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 13.7663 - val_loss: 17.6321\n",
      "Train: 0.39557813157856586\n",
      "Val  : 0.30584141231740425\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 13.6796 - val_loss: 17.5964\n",
      "Train: 0.3962785635801145\n",
      "Val  : 0.3059803618690308\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 13.5938 - val_loss: 17.5614\n",
      "Train: 0.39697848999228896\n",
      "Val  : 0.30614036185800286\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 13.5091 - val_loss: 17.5273\n",
      "Train: 0.39765859253101915\n",
      "Val  : 0.3062823419747713\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 13.4250 - val_loss: 17.4932\n",
      "Train: 0.39834781201848646\n",
      "Val  : 0.3064286063482418\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 13.3415 - val_loss: 17.4597\n",
      "Train: 0.39904133981206885\n",
      "Val  : 0.3065513216347817\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 13.2591 - val_loss: 17.4267\n",
      "Train: 0.3997201383935053\n",
      "Val  : 0.306683458328538\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 13.1774 - val_loss: 17.3940\n",
      "Train: 0.40041127279613253\n",
      "Val  : 0.3068077111889774\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 13.0964 - val_loss: 17.3618\n",
      "Train: 0.401082124514192\n",
      "Val  : 0.3069277871736664\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 13.0162 - val_loss: 17.3299\n",
      "Train: 0.4017600557405243\n",
      "Val  : 0.3070735427567419\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 12.9366 - val_loss: 17.2988\n",
      "Train: 0.40243320172639296\n",
      "Val  : 0.30718767199009783\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 12.8579 - val_loss: 17.2679\n",
      "Train: 0.4031002221931274\n",
      "Val  : 0.30731448538265804\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 12.7796 - val_loss: 17.2372\n",
      "Train: 0.4037686885346087\n",
      "Val  : 0.307441299475305\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 12.7020 - val_loss: 17.2071\n",
      "Train: 0.4044248433163477\n",
      "Val  : 0.30756186700018395\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 12.6252 - val_loss: 17.1769\n",
      "Train: 0.40508267768956274\n",
      "Val  : 0.3076799037355885\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 12.5489 - val_loss: 17.1476\n",
      "Train: 0.4057331145763161\n",
      "Val  : 0.3077959411202566\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 12.4733 - val_loss: 17.1185\n",
      "Train: 0.40637666631689556\n",
      "Val  : 0.30790253484909536\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 12.3985 - val_loss: 17.0899\n",
      "Train: 0.4070245587747494\n",
      "Val  : 0.30799402854134916\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 12.3241 - val_loss: 17.0615\n",
      "Train: 0.407673369971645\n",
      "Val  : 0.3081029659811871\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4955 [==============================] - 0s 78us/step - loss: 12.2503 - val_loss: 17.0334\n",
      "Train: 0.40832607939353555\n",
      "Val  : 0.308209280027557\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 12.1774 - val_loss: 17.0055\n",
      "Train: 0.40895640094773683\n",
      "Val  : 0.3083089339121723\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 12.1049 - val_loss: 16.9782\n",
      "Train: 0.40959171976931136\n",
      "Val  : 0.30840213316582377\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 12.0330 - val_loss: 16.9509\n",
      "Train: 0.41022749818494575\n",
      "Val  : 0.3084908688161777\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 11.9616 - val_loss: 16.9240\n",
      "Train: 0.41085240964904385\n",
      "Val  : 0.30855742539335396\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 11.8908 - val_loss: 16.8974\n",
      "Train: 0.4114773871181538\n",
      "Val  : 0.3086375649944462\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 11.8206 - val_loss: 16.8712\n",
      "Train: 0.4121047415635626\n",
      "Val  : 0.3087140146793076\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 11.7508 - val_loss: 16.8451\n",
      "Train: 0.41272038325890054\n",
      "Val  : 0.3087856364696545\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 11.6816 - val_loss: 16.8196\n",
      "Train: 0.4133507392323305\n",
      "Val  : 0.308858593543044\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 11.6130 - val_loss: 16.7942\n",
      "Train: 0.4139593379728422\n",
      "Val  : 0.30894307013549055\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 11.5449 - val_loss: 16.7692\n",
      "Train: 0.41457076562874257\n",
      "Val  : 0.30901243002294454\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 11.4773 - val_loss: 16.7444\n",
      "Train: 0.4151863095737074\n",
      "Val  : 0.30907918435259163\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 11.4104 - val_loss: 16.7197\n",
      "Train: 0.4157955310165774\n",
      "Val  : 0.3091541334852548\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 11.3440 - val_loss: 16.6953\n",
      "Train: 0.4164036865880583\n",
      "Val  : 0.30922317696548896\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 11.2779 - val_loss: 16.6712\n",
      "Train: 0.41700730934835245\n",
      "Val  : 0.3092871914633216\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 11.2125 - val_loss: 16.6475\n",
      "Train: 0.41761453018607886\n",
      "Val  : 0.3093508164438169\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 11.1477 - val_loss: 16.6239\n",
      "Train: 0.4182235568832338\n",
      "Val  : 0.30941095107771155\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 11.0831 - val_loss: 16.6008\n",
      "Train: 0.4188246957430578\n",
      "Val  : 0.3094562669153301\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 11.0191 - val_loss: 16.5778\n",
      "Train: 0.41941297840179004\n",
      "Val  : 0.3095167801835557\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 10.9554 - val_loss: 16.5546\n",
      "Train: 0.42001070707545335\n",
      "Val  : 0.30958481207932026\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 10.8924 - val_loss: 16.5320\n",
      "Train: 0.42061286533800646\n",
      "Val  : 0.3096311911783353\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 10.8296 - val_loss: 16.5094\n",
      "Train: 0.4212159549658315\n",
      "Val  : 0.3096822337604106\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 10.7673 - val_loss: 16.4873\n",
      "Train: 0.4218143487529444\n",
      "Val  : 0.30972862714641725\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 10.7057 - val_loss: 16.4654\n",
      "Train: 0.4224103523619785\n",
      "Val  : 0.3097787625167827\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 10.6443 - val_loss: 16.4437\n",
      "Train: 0.4229989341246288\n",
      "Val  : 0.3098090093839829\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 10.5835 - val_loss: 16.4220\n",
      "Train: 0.4235917506879814\n",
      "Val  : 0.3098553617075308\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 10.5232 - val_loss: 16.4007\n",
      "Train: 0.42418489383184593\n",
      "Val  : 0.30989159937557936\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 10.4631 - val_loss: 16.3795\n",
      "Train: 0.4247691555024303\n",
      "Val  : 0.3099351327892133\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 10.4036 - val_loss: 16.3586\n",
      "Train: 0.42535824168525815\n",
      "Val  : 0.3099938258546907\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 10.3444 - val_loss: 16.3376\n",
      "Train: 0.42594473283678325\n",
      "Val  : 0.31004925291459784\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 10.2858 - val_loss: 16.3170\n",
      "Train: 0.42652712156847966\n",
      "Val  : 0.3100857331370215\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 10.2275 - val_loss: 16.2968\n",
      "Train: 0.42710862254174375\n",
      "Val  : 0.3101302459535794\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 10.1696 - val_loss: 16.2766\n",
      "Train: 0.4277049385017645\n",
      "Val  : 0.31017584678503096\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 10.1121 - val_loss: 16.2567\n",
      "Train: 0.42829764069533166\n",
      "Val  : 0.31021560213527827\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 10.0551 - val_loss: 16.2369\n",
      "Train: 0.42888739182986263\n",
      "Val  : 0.31025789173891427\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 9.9983 - val_loss: 16.2174\n",
      "Train: 0.42947470838835977\n",
      "Val  : 0.31029285700196885\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 9.9421 - val_loss: 16.1982\n",
      "Train: 0.4300659941413484\n",
      "Val  : 0.31032812252743897\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 9.8862 - val_loss: 16.1787\n",
      "Train: 0.4306607885635458\n",
      "Val  : 0.3103782744354414\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 9.8306 - val_loss: 16.1597\n",
      "Train: 0.4312481847523568\n",
      "Val  : 0.3104272914788488\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 9.7755 - val_loss: 16.1408\n",
      "Train: 0.4318341595384936\n",
      "Val  : 0.3104786591845926\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4955 [==============================] - 0s 68us/step - loss: 9.7208 - val_loss: 16.1222\n",
      "Train: 0.4324175204578054\n",
      "Val  : 0.31052144332936094\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 9.6665 - val_loss: 16.1037\n",
      "Train: 0.4330085999109435\n",
      "Val  : 0.310564750774515\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 9.6125 - val_loss: 16.0852\n",
      "Train: 0.43359380687453025\n",
      "Val  : 0.31060668876563663\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 9.5589 - val_loss: 16.0671\n",
      "Train: 0.4341854712852202\n",
      "Val  : 0.31064200281467547\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 9.5056 - val_loss: 16.0488\n",
      "Train: 0.43477190100423424\n",
      "Val  : 0.31069403468043005\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 9.4529 - val_loss: 16.0310\n",
      "Train: 0.43536170952061926\n",
      "Val  : 0.3107402389293139\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 9.4003 - val_loss: 16.0133\n",
      "Train: 0.4359425503414076\n",
      "Val  : 0.310774707399144\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 9.3481 - val_loss: 15.9958\n",
      "Train: 0.4365264623754258\n",
      "Val  : 0.3108208115728972\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 9.2963 - val_loss: 15.9783\n",
      "Train: 0.4371220364283767\n",
      "Val  : 0.3108618122881534\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 9.2448 - val_loss: 15.9610\n",
      "Train: 0.43771403521799584\n",
      "Val  : 0.3109080433242487\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 9.1936 - val_loss: 15.9437\n",
      "Train: 0.438302894773729\n",
      "Val  : 0.3109489454502306\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 9.1428 - val_loss: 15.9269\n",
      "Train: 0.43889626554693517\n",
      "Val  : 0.3109822849906777\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 9.0924 - val_loss: 15.9101\n",
      "Train: 0.43949233797630133\n",
      "Val  : 0.3110117582535858\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 9.0423 - val_loss: 15.8936\n",
      "Train: 0.4400866950487639\n",
      "Val  : 0.31103961983467127\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 8.9926 - val_loss: 15.8771\n",
      "Train: 0.4406791038764445\n",
      "Val  : 0.3110687475040958\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 8.9431 - val_loss: 15.8608\n",
      "Train: 0.44127611467008365\n",
      "Val  : 0.31111903920222905\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 8.8940 - val_loss: 15.8446\n",
      "Train: 0.4418772874146126\n",
      "Val  : 0.3111548155125933\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 8.8451 - val_loss: 15.8285\n",
      "Train: 0.44247866724126395\n",
      "Val  : 0.31118748457280043\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 8.7966 - val_loss: 15.8127\n",
      "Train: 0.4430724232991038\n",
      "Val  : 0.3112213338197342\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.7484 - val_loss: 15.7970\n",
      "Train: 0.4436670264865065\n",
      "Val  : 0.31125631595739534\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 8.7005 - val_loss: 15.7812\n",
      "Train: 0.4442700520241\n",
      "Val  : 0.3113011615978508\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.6530 - val_loss: 15.7659\n",
      "Train: 0.4448711760314242\n",
      "Val  : 0.3113357238313727\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 8.6059 - val_loss: 15.7506\n",
      "Train: 0.44547648333613465\n",
      "Val  : 0.31138080943051316\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.5590 - val_loss: 15.7356\n",
      "Train: 0.4460710870762036\n",
      "Val  : 0.31142222466355257\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 8.5123 - val_loss: 15.7206\n",
      "Train: 0.4466745688980001\n",
      "Val  : 0.3114471345450183\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.4660 - val_loss: 15.7058\n",
      "Train: 0.447273894914984\n",
      "Val  : 0.31147448211313694\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 8.4201 - val_loss: 15.6909\n",
      "Train: 0.44787410380013715\n",
      "Val  : 0.3114994694300778\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.3742 - val_loss: 15.6762\n",
      "Train: 0.4484807735736645\n",
      "Val  : 0.31153553571051384\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 8.3288 - val_loss: 15.6618\n",
      "Train: 0.44909388122311444\n",
      "Val  : 0.3115647857499958\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.2837 - val_loss: 15.6476\n",
      "Train: 0.44970431341761524\n",
      "Val  : 0.31160159012542626\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 8.2387 - val_loss: 15.6333\n",
      "Train: 0.4503241807990091\n",
      "Val  : 0.3116458764180101\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 8.1942 - val_loss: 15.6193\n",
      "Train: 0.45093855320921017\n",
      "Val  : 0.31167370731425537\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 8.1498 - val_loss: 15.6052\n",
      "Train: 0.4515476346924289\n",
      "Val  : 0.3117170197828018\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 8.1058 - val_loss: 15.5915\n",
      "Train: 0.45217010525335793\n",
      "Val  : 0.31173364909638185\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 8.0620 - val_loss: 15.5778\n",
      "Train: 0.4527906020813272\n",
      "Val  : 0.3117615095822257\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 8.0186 - val_loss: 15.5640\n",
      "Train: 0.4534114974136123\n",
      "Val  : 0.31180548832412414\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 7.9753 - val_loss: 15.5506\n",
      "Train: 0.45402524563682406\n",
      "Val  : 0.3118333146887495\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 7.9325 - val_loss: 15.5371\n",
      "Train: 0.4546405548497027\n",
      "Val  : 0.31185477669444017\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 7.8899 - val_loss: 15.5237\n",
      "Train: 0.4552640201360416\n",
      "Val  : 0.31188790441219605\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 7.8474 - val_loss: 15.5105\n",
      "Train: 0.45589558891054477\n",
      "Val  : 0.31193556170129283\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 7.8053 - val_loss: 15.4973\n",
      "Train: 0.45652133878637596\n",
      "Val  : 0.3119800278424228\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 7.7634 - val_loss: 15.4844\n",
      "Train: 0.4571486891834906\n",
      "Val  : 0.3120039508050215\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 7.7219 - val_loss: 15.4718\n",
      "Train: 0.4577727843217004\n",
      "Val  : 0.31203634422468596\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 7.6805 - val_loss: 15.4592\n",
      "Train: 0.4584105890751346\n",
      "Val  : 0.31207161392038435\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.6394 - val_loss: 15.4466\n",
      "Train: 0.45903738406559924\n",
      "Val  : 0.31209987514451065\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.5986 - val_loss: 15.4340\n",
      "Train: 0.4596714549633052\n",
      "Val  : 0.31212548733855605\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 7.5580 - val_loss: 15.4216\n",
      "Train: 0.4602983754063682\n",
      "Val  : 0.31216087416232285\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 80us/step - loss: 7.5177 - val_loss: 15.4093\n",
      "Train: 0.46094123037325174\n",
      "Val  : 0.3121832951628705\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 7.4775 - val_loss: 15.3971\n",
      "Train: 0.4615776797164175\n",
      "Val  : 0.31222150563866624\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.4377 - val_loss: 15.3851\n",
      "Train: 0.46221515846207034\n",
      "Val  : 0.31225042903369804\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 7.3981 - val_loss: 15.3731\n",
      "Train: 0.46286478557108923\n",
      "Val  : 0.3122807015301342\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 7.3588 - val_loss: 15.3613\n",
      "Train: 0.4635080566972082\n",
      "Val  : 0.31232640169854076\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 7.3196 - val_loss: 15.3495\n",
      "Train: 0.46414867224976025\n",
      "Val  : 0.3123631042645413\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.2807 - val_loss: 15.3378\n",
      "Train: 0.464793676783272\n",
      "Val  : 0.3123886459540809\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.2421 - val_loss: 15.3262\n",
      "Train: 0.4654514216268663\n",
      "Val  : 0.3124356747048474\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.2036 - val_loss: 15.3148\n",
      "Train: 0.4661006427963927\n",
      "Val  : 0.3124724001031656\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 7.1655 - val_loss: 15.3035\n",
      "Train: 0.46675318066517607\n",
      "Val  : 0.31251223794355976\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 7.1276 - val_loss: 15.2921\n",
      "Train: 0.46740462047391934\n",
      "Val  : 0.31254615602855007\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 7.0898 - val_loss: 15.2810\n",
      "Train: 0.4680515081626181\n",
      "Val  : 0.3125693088427812\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 7.0524 - val_loss: 15.2699\n",
      "Train: 0.4687105263279188\n",
      "Val  : 0.3125855833745314\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 81us/step - loss: 7.0150 - val_loss: 15.2591\n",
      "Train: 0.4693640551897218\n",
      "Val  : 0.31261781693599494\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 6.9780 - val_loss: 15.2483\n",
      "Train: 0.47002127986303455\n",
      "Val  : 0.3126335911243378\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 6.9412 - val_loss: 15.2376\n",
      "Train: 0.47068670618582364\n",
      "Val  : 0.3126651844923673\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 6.9046 - val_loss: 15.2271\n",
      "Train: 0.4713374959615253\n",
      "Val  : 0.3126923009942338\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 6.8683 - val_loss: 15.2165\n",
      "Train: 0.47200325674620514\n",
      "Val  : 0.3127281462537213\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 75us/step - loss: 6.8321 - val_loss: 15.2060\n",
      "Train: 0.4726693762239258\n",
      "Val  : 0.3127602843482755\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 6.7960 - val_loss: 15.1957\n",
      "Train: 0.47333786674354994\n",
      "Val  : 0.3127852883744675\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 6.7603 - val_loss: 15.1855\n",
      "Train: 0.4740089570765104\n",
      "Val  : 0.31282199617337825\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 6.7248 - val_loss: 15.1753\n",
      "Train: 0.47468596454960876\n",
      "Val  : 0.3128544394421841\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 6.6895 - val_loss: 15.1651\n",
      "Train: 0.4753616669838019\n",
      "Val  : 0.31288344232002385\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 6.6543 - val_loss: 15.1551\n",
      "Train: 0.47603619804376235\n",
      "Val  : 0.31291043097623533\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 82us/step - loss: 6.6194 - val_loss: 15.1452\n",
      "Train: 0.4767161245155879\n",
      "Val  : 0.31294565716822603\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 6.5847 - val_loss: 15.1354\n",
      "Train: 0.4773991791920296\n",
      "Val  : 0.31296331834846053\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 6.5502 - val_loss: 15.1255\n",
      "Train: 0.4780744819656927\n",
      "Val  : 0.3130002673657597\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 6.5159 - val_loss: 15.1157\n",
      "Train: 0.4787590679223346\n",
      "Val  : 0.3130319142428119\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 6.4818 - val_loss: 15.1062\n",
      "Train: 0.4794447917150654\n",
      "Val  : 0.31305810645882687\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 78us/step - loss: 6.4480 - val_loss: 15.0968\n",
      "Train: 0.4801288450657401\n",
      "Val  : 0.31307437454393133\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 6.4143 - val_loss: 15.0874\n",
      "Train: 0.48081481753183986\n",
      "Val  : 0.3131042105152438\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 6.3809 - val_loss: 15.0781\n",
      "Train: 0.48150861730815603\n",
      "Val  : 0.3131314139430195\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 6.3476 - val_loss: 15.0688\n",
      "Train: 0.4822072477161108\n",
      "Val  : 0.31315354412385993\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4955 [==============================] - 0s 79us/step - loss: 6.3144 - val_loss: 15.0597\n",
      "Train: 0.48289300669182433\n",
      "Val  : 0.31318055958594215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ALLOW NEGATIVE WEIGHTS!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='linear')(diff_vecs)\n",
    "#w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.21486070403938934\n",
      "Val  : 0.19116040983278643\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 1s 334us/step - loss: 24.5550 - val_loss: 24.6202\n",
      "Train: 0.2995279889056084\n",
      "Val  : 0.30702629784746893\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 23.9586 - val_loss: 23.8623\n",
      "Train: 0.29985185119603186\n",
      "Val  : 0.3074264478740778\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 22.9311 - val_loss: 22.8220\n",
      "Train: 0.30121788882811185\n",
      "Val  : 0.30870834138315695\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 21.6996 - val_loss: 21.7461\n",
      "Train: 0.30458318768682463\n",
      "Val  : 0.31093665105952567\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 68us/step - loss: 20.6118 - val_loss: 20.8558\n",
      "Train: 0.3103197791322965\n",
      "Val  : 0.31495369410376356\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 19.6849 - val_loss: 20.0551\n",
      "Train: 0.31463472998421205\n",
      "Val  : 0.3173902248399199\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 68us/step - loss: 18.8147 - val_loss: 19.2751\n",
      "Train: 0.3162040139547034\n",
      "Val  : 0.31716823641205893\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 17.9801 - val_loss: 18.5332\n",
      "Train: 0.31516097183986785\n",
      "Val  : 0.31439512897556926\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 17.1843 - val_loss: 17.8222\n",
      "Train: 0.3133055303373754\n",
      "Val  : 0.3103076624479126\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 16.4230 - val_loss: 17.1552\n",
      "Train: 0.3107443465926542\n",
      "Val  : 0.3053433765945009\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 15.7005 - val_loss: 16.5282\n",
      "Train: 0.30785853140626723\n",
      "Val  : 0.3001040241798314\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 15.0078 - val_loss: 15.9339\n",
      "Train: 0.3051084797253805\n",
      "Val  : 0.2949109634337361\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 14.3478 - val_loss: 15.3748\n",
      "Train: 0.30250985690932275\n",
      "Val  : 0.28989439037378045\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 13.7255 - val_loss: 14.8498\n",
      "Train: 0.3009274904945162\n",
      "Val  : 0.28610541644170107\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 13.1314 - val_loss: 14.3459\n",
      "Train: 0.29935422603058376\n",
      "Val  : 0.28244717077119874\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 12.5731 - val_loss: 13.8813\n",
      "Train: 0.29823524710335336\n",
      "Val  : 0.27946409329656974\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 12.0478 - val_loss: 13.4439\n",
      "Train: 0.2977465209446358\n",
      "Val  : 0.27713178195910115\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 11.5527 - val_loss: 13.0272\n",
      "Train: 0.29797642108093036\n",
      "Val  : 0.27567742710025706\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 11.0869 - val_loss: 12.6355\n",
      "Train: 0.2982129640982679\n",
      "Val  : 0.27429584669698326\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 10.6461 - val_loss: 12.2674\n",
      "Train: 0.29856424534491655\n",
      "Val  : 0.27285831962667356\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 10.2344 - val_loss: 11.9215\n",
      "Train: 0.2999490494645285\n",
      "Val  : 0.2722864705021586\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.8422 - val_loss: 11.5953\n",
      "Train: 0.30150438896254583\n",
      "Val  : 0.2719020485999005\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.4739 - val_loss: 11.2876\n",
      "Train: 0.3037842736539481\n",
      "Val  : 0.2721633148344078\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.1277 - val_loss: 10.9965\n",
      "Train: 0.3057925119644128\n",
      "Val  : 0.2721323726364735\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 8.7970 - val_loss: 10.7223\n",
      "Train: 0.30836565670779686\n",
      "Val  : 0.27238556593931357\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.4847 - val_loss: 10.4608\n",
      "Train: 0.31267882195677943\n",
      "Val  : 0.2743208329508153\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 8.1881 - val_loss: 10.2131\n",
      "Train: 0.3169053441939522\n",
      "Val  : 0.2760227295874392\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.9079 - val_loss: 9.9813\n",
      "Train: 0.31991598194378734\n",
      "Val  : 0.27618364279804\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 7.6374 - val_loss: 9.7600\n",
      "Train: 0.32492849677592656\n",
      "Val  : 0.27837909876756234\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 7.3805 - val_loss: 9.5532\n",
      "Train: 0.33004547977874626\n",
      "Val  : 0.2804950425444201\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.1366 - val_loss: 9.3523\n",
      "Train: 0.33381754367936856\n",
      "Val  : 0.2814132473421336\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.9018 - val_loss: 9.1657\n",
      "Train: 0.33871856126727273\n",
      "Val  : 0.28306322799845995\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.6788 - val_loss: 8.9882\n",
      "Train: 0.34407323760469205\n",
      "Val  : 0.2850194121848451\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.4642 - val_loss: 8.8172\n",
      "Train: 0.34933392205608893\n",
      "Val  : 0.28703588611177555\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.2599 - val_loss: 8.6589\n",
      "Train: 0.3541200060985258\n",
      "Val  : 0.2880308075724448\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.0619 - val_loss: 8.5075\n",
      "Train: 0.3597261568756897\n",
      "Val  : 0.2900368894519693\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 5.8736 - val_loss: 8.3592\n",
      "Train: 0.3650504637829989\n",
      "Val  : 0.29161428219236923\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 5.6927 - val_loss: 8.2223\n",
      "Train: 0.3704087204010137\n",
      "Val  : 0.2929812936772768\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 5.5197 - val_loss: 8.0941\n",
      "Train: 0.3765829045099921\n",
      "Val  : 0.295241176257259\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 5.3522 - val_loss: 7.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.38184672613454307\n",
      "Val  : 0.2964770783050034\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 5.1920 - val_loss: 7.8498\n",
      "Train: 0.38818629206469385\n",
      "Val  : 0.2987747924325636\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 5.0391 - val_loss: 7.7379\n",
      "Train: 0.39435281792919796\n",
      "Val  : 0.30065200479609827\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 4.8905 - val_loss: 7.6363\n",
      "Train: 0.3995923692502213\n",
      "Val  : 0.30160676196435066\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 4.7480 - val_loss: 7.5352\n",
      "Train: 0.4047215632991593\n",
      "Val  : 0.3024332656916667\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 4.6116 - val_loss: 7.4425\n",
      "Train: 0.4114576891968523\n",
      "Val  : 0.3046558494120956\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 4.4794 - val_loss: 7.3516\n",
      "Train: 0.4177105870080813\n",
      "Val  : 0.3063358947650581\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 4.3522 - val_loss: 7.2674\n",
      "Train: 0.4237025793032785\n",
      "Val  : 0.3076498957574809\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 4.2291 - val_loss: 7.1859\n",
      "Train: 0.43015994074980735\n",
      "Val  : 0.30962361735416527\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 4.1116 - val_loss: 7.1101\n",
      "Train: 0.43558475285025744\n",
      "Val  : 0.3101926817960777\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 3.9975 - val_loss: 7.0361\n",
      "Train: 0.4421341349893465\n",
      "Val  : 0.31200945675902264\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 3.8891 - val_loss: 6.9680\n",
      "Train: 0.44819598354999873\n",
      "Val  : 0.31343797454627415\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 3.7826 - val_loss: 6.9011\n",
      "Train: 0.4544091038146259\n",
      "Val  : 0.31500701196877423\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 3.6813 - val_loss: 6.8390\n",
      "Train: 0.4605909248689405\n",
      "Val  : 0.31634990369177907\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 3.5815 - val_loss: 6.7827\n",
      "Train: 0.46706036854652194\n",
      "Val  : 0.3179307960812701\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 3.4867 - val_loss: 6.7286\n",
      "Train: 0.4729212309983325\n",
      "Val  : 0.3191576557318331\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 3.3957 - val_loss: 6.6753\n",
      "Train: 0.4782526024297947\n",
      "Val  : 0.3195832839684074\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 3.3066 - val_loss: 6.6271\n",
      "Train: 0.4834726489853312\n",
      "Val  : 0.3197944929470962\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 3.2201 - val_loss: 6.5801\n",
      "Train: 0.49076272220858475\n",
      "Val  : 0.3223005210613343\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 3.1377 - val_loss: 6.5358\n",
      "Train: 0.4965643680715837\n",
      "Val  : 0.323111823790921\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 3.0570 - val_loss: 6.4938\n",
      "Train: 0.5021909810751519\n",
      "Val  : 0.3237181069148135\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 2.9787 - val_loss: 6.4539\n",
      "Train: 0.5079802496690025\n",
      "Val  : 0.3244621388531974\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 2.9020 - val_loss: 6.4152\n",
      "Train: 0.5141399041372374\n",
      "Val  : 0.3258660392791579\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 2.8311 - val_loss: 6.3816\n",
      "Train: 0.52008563330087\n",
      "Val  : 0.3267649587256623\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 2.7584 - val_loss: 6.3477\n",
      "Train: 0.5249184092551281\n",
      "Val  : 0.32658890312822125\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 67us/step - loss: 2.6903 - val_loss: 6.3143\n",
      "Train: 0.5316633961969081\n",
      "Val  : 0.3288931525636998\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 68us/step - loss: 2.6243 - val_loss: 6.2822\n",
      "Train: 0.5370870358670731\n",
      "Val  : 0.32935276687709736\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 2.5593 - val_loss: 6.2511\n",
      "Train: 0.5427916356685979\n",
      "Val  : 0.3301312346853134\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 65us/step - loss: 2.4963 - val_loss: 6.2211\n",
      "Train: 0.548182614333797\n",
      "Val  : 0.3308015471401505\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 65us/step - loss: 2.4352 - val_loss: 6.1948\n",
      "Train: 0.5534857920042898\n",
      "Val  : 0.3310735603068777\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 2.3772 - val_loss: 6.1703\n",
      "Train: 0.5590897491944434\n",
      "Val  : 0.33185512711144327\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 68us/step - loss: 2.3190 - val_loss: 6.1470\n",
      "Train: 0.5644670069052095\n",
      "Val  : 0.3321726952321564\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 2.2632 - val_loss: 6.1231\n",
      "Train: 0.5705060292959431\n",
      "Val  : 0.33349174655510466\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 2.2104 - val_loss: 6.0988\n",
      "Train: 0.5761514831514125\n",
      "Val  : 0.33419888220652283\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 2.1565 - val_loss: 6.0803\n",
      "Train: 0.5810386672971091\n",
      "Val  : 0.3342481735991664\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 2.1064 - val_loss: 6.0615\n",
      "Train: 0.5872229007935837\n",
      "Val  : 0.335752613806258\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 2.0566 - val_loss: 6.0406\n",
      "Train: 0.5925365064854288\n",
      "Val  : 0.3363726422169906\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 2.0083 - val_loss: 6.0270\n",
      "Train: 0.5976247015799205\n",
      "Val  : 0.3366829628686153\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 1.9629 - val_loss: 6.0095\n",
      "Train: 0.6029572164397562\n",
      "Val  : 0.3370591067325823\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 1.9162 - val_loss: 5.9943\n",
      "Train: 0.6083502871994007\n",
      "Val  : 0.3379069067715221\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 1.8715 - val_loss: 5.9814\n",
      "Train: 0.6138903461658684\n",
      "Val  : 0.33905080516615876\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4220/4220 [==============================] - 0s 72us/step - loss: 1.8290 - val_loss: 5.9683\n",
      "Train: 0.619206916022907\n",
      "Val  : 0.33957242815632355\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 1.7874 - val_loss: 5.9533\n",
      "Train: 0.6233710425597413\n",
      "Val  : 0.3388942100233664\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 1.7467 - val_loss: 5.9389\n",
      "Train: 0.6294708206586486\n",
      "Val  : 0.34101462320285403\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 1.7061 - val_loss: 5.9271\n",
      "Train: 0.6330992424464574\n",
      "Val  : 0.3393171377364805\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.6684 - val_loss: 5.9118\n",
      "Train: 0.6388077665697227\n",
      "Val  : 0.34070696556996266\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 1.6302 - val_loss: 5.9044\n",
      "Train: 0.6441036551836701\n",
      "Val  : 0.3414765408183097\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 1.5933 - val_loss: 5.8950\n",
      "Train: 0.648310560491734\n",
      "Val  : 0.34091766538937796\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 1.5574 - val_loss: 5.8876\n",
      "Train: 0.653987056551754\n",
      "Val  : 0.34239095724468727\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 1.5237 - val_loss: 5.8792\n",
      "Train: 0.6590001038235508\n",
      "Val  : 0.3427178503473097\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.4896 - val_loss: 5.8725\n",
      "Train: 0.663543618928056\n",
      "Val  : 0.3427644693674062\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 1.4566 - val_loss: 5.8613\n",
      "Train: 0.6678254263746003\n",
      "Val  : 0.34227478944261136\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 1.4239 - val_loss: 5.8529\n",
      "Train: 0.6732422915528786\n",
      "Val  : 0.3435446476868824\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.3933 - val_loss: 5.8486\n",
      "Train: 0.6778913342809082\n",
      "Val  : 0.3442136530449273\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 1.3622 - val_loss: 5.8443\n",
      "Train: 0.6820049352182979\n",
      "Val  : 0.3438184314799863\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 1.3324 - val_loss: 5.8385\n",
      "Train: 0.6870438128222279\n",
      "Val  : 0.3448518709076042\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 1.3033 - val_loss: 5.8335\n",
      "Train: 0.6917653210266246\n",
      "Val  : 0.3457957316932498\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 1.2757 - val_loss: 5.8292\n",
      "Train: 0.6962505540689529\n",
      "Val  : 0.34619504473614937\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 1.2486 - val_loss: 5.8255\n",
      "Train: 0.7000743528987113\n",
      "Val  : 0.34520771294773767\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.2206 - val_loss: 5.8213\n",
      "Train: 0.7045940514231087\n",
      "Val  : 0.3452774971254443\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.1946 - val_loss: 5.8161\n",
      "Train: 0.7086785706948384\n",
      "Val  : 0.34561271589100495\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.1697 - val_loss: 5.8138\n",
      "Train: 0.7129314494572911\n",
      "Val  : 0.34571952971156833\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 1.1447 - val_loss: 5.8110\n",
      "Train: 0.7176988851169477\n",
      "Val  : 0.3471360836154248\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 1.1208 - val_loss: 5.8136\n",
      "Train: 0.7215956957210925\n",
      "Val  : 0.3462845797173819\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 1.0964 - val_loss: 5.8133\n",
      "Train: 0.7256169958883816\n",
      "Val  : 0.34623694814193073\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 1.0736 - val_loss: 5.8102\n",
      "Train: 0.7298366401175049\n",
      "Val  : 0.3466263572411543\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 1.0510 - val_loss: 5.8101\n",
      "Train: 0.7330981742186944\n",
      "Val  : 0.34569047135790937\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 1.0291 - val_loss: 5.8132\n",
      "Train: 0.7376965786229854\n",
      "Val  : 0.3465105873560968\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 1.0078 - val_loss: 5.8151\n",
      "Train: 0.7415016390975302\n",
      "Val  : 0.34649120581744797\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.9868 - val_loss: 5.8161\n",
      "Train: 0.7459676692295515\n",
      "Val  : 0.3482211428157881\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.9664 - val_loss: 5.8190\n",
      "Train: 0.7493424300484924\n",
      "Val  : 0.34704915842240264\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.9462 - val_loss: 5.8196\n",
      "Train: 0.7533948081215143\n",
      "Val  : 0.34735834343180244\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.9274 - val_loss: 5.8239\n",
      "Train: 0.7570752949030023\n",
      "Val  : 0.347600443228024\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.9086 - val_loss: 5.8286\n",
      "Train: 0.7607478918067613\n",
      "Val  : 0.34752217215497533\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.8900 - val_loss: 5.8339\n",
      "Train: 0.7640504126828772\n",
      "Val  : 0.3472370868934725\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.8719 - val_loss: 5.8349\n",
      "Train: 0.7677142971178285\n",
      "Val  : 0.34751070458538097\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.8542 - val_loss: 5.8373\n",
      "Train: 0.7710926569122877\n",
      "Val  : 0.3470380175599369\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 0.8378 - val_loss: 5.8445\n",
      "Train: 0.7744091160342026\n",
      "Val  : 0.34630807058138585\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.8211 - val_loss: 5.8532\n",
      "Train: 0.77804953859122\n",
      "Val  : 0.3466494008118323\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.8043 - val_loss: 5.8605\n",
      "Train: 0.7819150774911\n",
      "Val  : 0.3475703948779987\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.7882 - val_loss: 5.8683\n",
      "Train: 0.7851297932010026\n",
      "Val  : 0.3476073789919473\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.7734 - val_loss: 5.8742\n",
      "Train: 0.7881893093136476\n",
      "Val  : 0.34674086108872054\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.7579 - val_loss: 5.8862\n",
      "Train: 0.791617478455094\n",
      "Val  : 0.3471819828220106\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.7433 - val_loss: 5.8809\n",
      "Train: 0.794875666783975\n",
      "Val  : 0.3478129998500372\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.7284 - val_loss: 5.8945\n",
      "Train: 0.7979049115399388\n",
      "Val  : 0.34737378902284904\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.7158 - val_loss: 5.8965\n",
      "Train: 0.8010054541862595\n",
      "Val  : 0.3467882442857057\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.7013 - val_loss: 5.9140\n",
      "Train: 0.8035899787192345\n",
      "Val  : 0.34582375068130883\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.6881 - val_loss: 5.9184\n",
      "Train: 0.8068940553976219\n",
      "Val  : 0.34642496260413946\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.6751 - val_loss: 5.9230\n",
      "Train: 0.8103188184275094\n",
      "Val  : 0.3472845152847897\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.6623 - val_loss: 5.9291\n",
      "Train: 0.8127496638763637\n",
      "Val  : 0.3465297626679511\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.6502 - val_loss: 5.9420\n",
      "Train: 0.8154824865135107\n",
      "Val  : 0.3461855018868412\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.6378 - val_loss: 5.9549\n",
      "Train: 0.8180776841156211\n",
      "Val  : 0.34577081893654754\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.6265 - val_loss: 5.9566\n",
      "Train: 0.8209661438055986\n",
      "Val  : 0.3459592344582315\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.6144 - val_loss: 5.9674\n",
      "Train: 0.8232737799076296\n",
      "Val  : 0.3450202646081074\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 67us/step - loss: 0.6034 - val_loss: 5.9731\n",
      "Train: 0.8263184948628766\n",
      "Val  : 0.3456022441679117\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.5920 - val_loss: 5.9843\n",
      "Train: 0.8292219211992131\n",
      "Val  : 0.3460493773508301\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.5814 - val_loss: 6.0001\n",
      "Train: 0.8312595445418428\n",
      "Val  : 0.3447813968032793\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.5712 - val_loss: 5.9990\n",
      "Train: 0.8338255039919547\n",
      "Val  : 0.3445142126020493\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.5612 - val_loss: 6.0146\n",
      "Train: 0.8364070286003226\n",
      "Val  : 0.34482307168615667\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.5505 - val_loss: 6.0273\n",
      "Train: 0.8384493795160748\n",
      "Val  : 0.3438903349238172\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.5407 - val_loss: 6.0317\n",
      "Train: 0.8408926040418803\n",
      "Val  : 0.34420853681149693\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.5316 - val_loss: 6.0475\n",
      "Train: 0.8435852751744886\n",
      "Val  : 0.3444588456278641\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.5225 - val_loss: 6.0509\n",
      "Train: 0.846157782858282\n",
      "Val  : 0.3452761211100682\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.5134 - val_loss: 6.0718\n",
      "Train: 0.8478915381379832\n",
      "Val  : 0.3440562516452713\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.5046 - val_loss: 6.0880\n",
      "Train: 0.8499766216468532\n",
      "Val  : 0.3434735005361798\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.4958 - val_loss: 6.0970\n",
      "Train: 0.8522687787341967\n",
      "Val  : 0.3433943099640056\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.4871 - val_loss: 6.1054\n",
      "Train: 0.853926762682244\n",
      "Val  : 0.3423809158400998\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.4792 - val_loss: 6.1148\n",
      "Train: 0.8565155692678669\n",
      "Val  : 0.34338915141120235\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 0.4713 - val_loss: 6.1241\n",
      "Train: 0.8586174236678555\n",
      "Val  : 0.34285737980757414\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.4635 - val_loss: 6.1494\n",
      "Train: 0.860830570651255\n",
      "Val  : 0.34334910873920405\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.4557 - val_loss: 6.1549\n",
      "Train: 0.8625273611226083\n",
      "Val  : 0.3425353131064697\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.4478 - val_loss: 6.1668\n",
      "Train: 0.8647671806748514\n",
      "Val  : 0.34312461897311103\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.4416 - val_loss: 6.1823\n",
      "Train: 0.8662690732973047\n",
      "Val  : 0.3420220320381675\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.4342 - val_loss: 6.1882\n",
      "Train: 0.8681348106049815\n",
      "Val  : 0.3416167385624599\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.4266 - val_loss: 6.2003\n",
      "Train: 0.8698466660130894\n",
      "Val  : 0.3416271083070762\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.4207 - val_loss: 6.2161\n",
      "Train: 0.8718284695218125\n",
      "Val  : 0.3419845660221844\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.4137 - val_loss: 6.2266\n",
      "Train: 0.8733749024056391\n",
      "Val  : 0.3412788528189261\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.4074 - val_loss: 6.2397\n",
      "Train: 0.8752605965212111\n",
      "Val  : 0.3409684785737296\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.4006 - val_loss: 6.2588\n",
      "Train: 0.8769258099207385\n",
      "Val  : 0.34103608601633534\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.3951 - val_loss: 6.2723\n",
      "Train: 0.8786611141408668\n",
      "Val  : 0.34136429874456425\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.3891 - val_loss: 6.2861\n",
      "Train: 0.8802061066373777\n",
      "Val  : 0.3407777957136814\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.3832 - val_loss: 6.2898\n",
      "Train: 0.8818136742872954\n",
      "Val  : 0.34029047107240634\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.3774 - val_loss: 6.3048\n",
      "Train: 0.8830848893479423\n",
      "Val  : 0.3392647036273114\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.3714 - val_loss: 6.3240\n",
      "Train: 0.8847737307633251\n",
      "Val  : 0.33973391172877987\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.3668 - val_loss: 6.3322\n",
      "Train: 0.8862643734275268\n",
      "Val  : 0.3395450792719792\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.3610 - val_loss: 6.3472\n",
      "Train: 0.8878946599645318\n",
      "Val  : 0.34045639100518704\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.3561 - val_loss: 6.3663\n",
      "Train: 0.8890641907905615\n",
      "Val  : 0.3390423863372134\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.3508 - val_loss: 6.3694\n",
      "Train: 0.8905586391444394\n",
      "Val  : 0.33909829314863454\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.3463 - val_loss: 6.3918\n",
      "Train: 0.8920227448918163\n",
      "Val  : 0.3392587521023244\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.3413 - val_loss: 6.4068\n",
      "Train: 0.8932685360848387\n",
      "Val  : 0.33839851826624395\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 0.3360 - val_loss: 6.4148\n",
      "Train: 0.8943272332117645\n",
      "Val  : 0.33812572715783423\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.3320 - val_loss: 6.4268\n",
      "Train: 0.8959408863108129\n",
      "Val  : 0.3387002007273401\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.3276 - val_loss: 6.4435\n",
      "Train: 0.8971202104347328\n",
      "Val  : 0.33912099639461274\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.3232 - val_loss: 6.4530\n",
      "Train: 0.8984242743117002\n",
      "Val  : 0.33877930708494974\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 0.3188 - val_loss: 6.4668\n",
      "Train: 0.8996189674368325\n",
      "Val  : 0.3387128800497785\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.3147 - val_loss: 6.4848\n",
      "Train: 0.9004609921148223\n",
      "Val  : 0.3376505788254469\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.3112 - val_loss: 6.4924\n",
      "Train: 0.9016429938450098\n",
      "Val  : 0.3373353538641383\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.3067 - val_loss: 6.5140\n",
      "Train: 0.9027358896808623\n",
      "Val  : 0.3370325264704622\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.3032 - val_loss: 6.5223\n",
      "Train: 0.9039387615388693\n",
      "Val  : 0.33714159699726753\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.2991 - val_loss: 6.5454\n",
      "Train: 0.9048578263412598\n",
      "Val  : 0.3366145142605416\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.2956 - val_loss: 6.5566\n",
      "Train: 0.905979162374179\n",
      "Val  : 0.33687882632282967\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.2922 - val_loss: 6.5693\n",
      "Train: 0.9068430780201144\n",
      "Val  : 0.33578506573697925\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.2885 - val_loss: 6.5898\n",
      "Train: 0.9079583241471824\n",
      "Val  : 0.3359313095371862\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.2854 - val_loss: 6.5944\n",
      "Train: 0.9089077424913018\n",
      "Val  : 0.33592114766550607\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.2821 - val_loss: 6.6174\n",
      "Train: 0.9097674357443133\n",
      "Val  : 0.3351190603009464\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.2785 - val_loss: 6.6306\n",
      "Train: 0.9108590184106217\n",
      "Val  : 0.3357996057989767\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.2759 - val_loss: 6.6505\n",
      "Train: 0.9115686325338827\n",
      "Val  : 0.33452930369121225\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.2724 - val_loss: 6.6634\n",
      "Train: 0.9126513579370014\n",
      "Val  : 0.3353417544043531\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.2697 - val_loss: 6.6784\n",
      "Train: 0.9133076531478742\n",
      "Val  : 0.3345017204716333\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.2670 - val_loss: 6.6900\n",
      "Train: 0.914305690597249\n",
      "Val  : 0.33436481216650976\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 0.2644 - val_loss: 6.7084\n",
      "Train: 0.915066491161407\n",
      "Val  : 0.33418779470568705\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 69us/step - loss: 0.2614 - val_loss: 6.7198\n",
      "Train: 0.9159247558734992\n",
      "Val  : 0.3341201150605192\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 0.2588 - val_loss: 6.7311\n",
      "Train: 0.9164472879872728\n",
      "Val  : 0.33351731775129256\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.2563 - val_loss: 6.7498\n",
      "Train: 0.9172642517479791\n",
      "Val  : 0.33306974897482605\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 0.2534 - val_loss: 6.7618\n",
      "Train: 0.9180020139732519\n",
      "Val  : 0.3330350562272494\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 0.2515 - val_loss: 6.7841\n",
      "Train: 0.9187046932577213\n",
      "Val  : 0.33270566808061425\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 68us/step - loss: 0.2492 - val_loss: 6.7940\n",
      "Train: 0.9195292516357987\n",
      "Val  : 0.3327087966235638\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.2465 - val_loss: 6.8062\n",
      "Train: 0.9201516385079092\n",
      "Val  : 0.33234388818799526\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 0.2444 - val_loss: 6.8241\n",
      "Train: 0.920831791298114\n",
      "Val  : 0.3320678047142364\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 0.2418 - val_loss: 6.8411\n",
      "Train: 0.9215226289569572\n",
      "Val  : 0.3322329743801774\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 0.2401 - val_loss: 6.8568\n",
      "Train: 0.9220721583376947\n",
      "Val  : 0.3313335498609855\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SHARED WEIGHTS!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "shared = Dense(d, activation='linear')\n",
    "\n",
    "u_w = shared(u_input)\n",
    "v_w = shared(v_input)\n",
    "\n",
    "w = keras.layers.add([u_w, v_w])\n",
    "\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.21712093552144557\n",
      "Val  : 0.15146658634265744\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 2s 366us/step - loss: 24.4389 - val_loss: 25.2146\n",
      "Train: 0.2925575347590198\n",
      "Val  : 0.28158716200874123\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 82us/step - loss: 23.9056 - val_loss: 24.4054\n",
      "Train: 0.2955284073854888\n",
      "Val  : 0.2836274878883054\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 22.9729 - val_loss: 23.3207\n",
      "Train: 0.29797627626481943\n",
      "Val  : 0.28463675592545246\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 21.8880 - val_loss: 22.2751\n",
      "Train: 0.3022257819219704\n",
      "Val  : 0.28661010784233426\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 20.9169 - val_loss: 21.4399\n",
      "Train: 0.3092933082318193\n",
      "Val  : 0.28896784009057436\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 20.0629 - val_loss: 20.7072\n",
      "Train: 0.3150200430345272\n",
      "Val  : 0.28917961737427605\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 19.2587 - val_loss: 20.0276\n",
      "Train: 0.3173983760733353\n",
      "Val  : 0.2864145141648976\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 18.4986 - val_loss: 19.4075\n",
      "Train: 0.3168814936503152\n",
      "Val  : 0.28252810017386587\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 17.8000 - val_loss: 18.8354\n",
      "Train: 0.3149615403731328\n",
      "Val  : 0.27879542922872924\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 17.1463 - val_loss: 18.3016\n",
      "Train: 0.3121326672747307\n",
      "Val  : 0.2744622340385964\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 16.5360 - val_loss: 17.8075\n",
      "Train: 0.3089674523228282\n",
      "Val  : 0.2702693859817063\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 15.9659 - val_loss: 17.3489\n",
      "Train: 0.3064764051156761\n",
      "Val  : 0.2671717752394155\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 15.4245 - val_loss: 16.9109\n",
      "Train: 0.30442866459256873\n",
      "Val  : 0.26484020732232494\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 14.9149 - val_loss: 16.5063\n",
      "Train: 0.3026153858965859\n",
      "Val  : 0.26255102500971533\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 14.4419 - val_loss: 16.1352\n",
      "Train: 0.30099837660364265\n",
      "Val  : 0.2603077620238947\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 13.9934 - val_loss: 15.7761\n",
      "Train: 0.29985815314206393\n",
      "Val  : 0.25883308087565515\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 13.5723 - val_loss: 15.4463\n",
      "Train: 0.29911409690168606\n",
      "Val  : 0.2576665879620581\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 13.1816 - val_loss: 15.1420\n",
      "Train: 0.29969391324981914\n",
      "Val  : 0.25785060319315056\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 12.8127 - val_loss: 14.8624\n",
      "Train: 0.2997054265949584\n",
      "Val  : 0.2567928289250342\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 12.4670 - val_loss: 14.6001\n",
      "Train: 0.30067524998176604\n",
      "Val  : 0.25670360631648415\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 12.1434 - val_loss: 14.3588\n",
      "Train: 0.30226766922623377\n",
      "Val  : 0.25718396928518383\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 82us/step - loss: 11.8415 - val_loss: 14.1373\n",
      "Train: 0.30414632632710475\n",
      "Val  : 0.2576618868383744\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 11.5583 - val_loss: 13.9351\n",
      "Train: 0.30655157571512637\n",
      "Val  : 0.25848236170619165\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 11.2939 - val_loss: 13.7443\n",
      "Train: 0.3086026157266268\n",
      "Val  : 0.25881924699030256\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 11.0460 - val_loss: 13.5709\n",
      "Train: 0.31149627997675505\n",
      "Val  : 0.2597269418741503\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 10.8144 - val_loss: 13.4127\n",
      "Train: 0.31515380814406396\n",
      "Val  : 0.261205990822128\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 10.5979 - val_loss: 13.2665\n",
      "Train: 0.31842818819513125\n",
      "Val  : 0.2623342992201782\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 10.3950 - val_loss: 13.1378\n",
      "Train: 0.3218373441224468\n",
      "Val  : 0.26315016381985373\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 10.2027 - val_loss: 13.0119\n",
      "Train: 0.3255382087850905\n",
      "Val  : 0.2643004372182395\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 10.0216 - val_loss: 12.8980\n",
      "Train: 0.32887684699411635\n",
      "Val  : 0.2649739586344681\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 9.8533 - val_loss: 12.7960\n",
      "Train: 0.33313578096488117\n",
      "Val  : 0.2664522484244231\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.6927 - val_loss: 12.6995\n",
      "Train: 0.3374712254064672\n",
      "Val  : 0.2680280174486335\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.5442 - val_loss: 12.6099\n",
      "Train: 0.3407924701481656\n",
      "Val  : 0.2682920891225621\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 9.4012 - val_loss: 12.5307\n",
      "Train: 0.34517899675265673\n",
      "Val  : 0.26962992946225356\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 9.2695 - val_loss: 12.4521\n",
      "Train: 0.3487801666677904\n",
      "Val  : 0.2702554293659075\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 9.1437 - val_loss: 12.3839\n",
      "Train: 0.3529482616057676\n",
      "Val  : 0.27138305711665783\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 9.0255 - val_loss: 12.3205\n",
      "Train: 0.3573232984652266\n",
      "Val  : 0.2724749076730637\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 8.9123 - val_loss: 12.2599\n",
      "Train: 0.36118870153143495\n",
      "Val  : 0.273330322212503\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.8073 - val_loss: 12.2006\n",
      "Train: 0.3650644346137217\n",
      "Val  : 0.2741461548798993\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.7056 - val_loss: 12.1514\n",
      "Train: 0.36965353667816553\n",
      "Val  : 0.275787168496695\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.6113 - val_loss: 12.1044\n",
      "Train: 0.3732707146823361\n",
      "Val  : 0.276240744359471\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 8.5209 - val_loss: 12.0593\n",
      "Train: 0.3766413174335043\n",
      "Val  : 0.27655999552222305\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.4362 - val_loss: 12.0164\n",
      "Train: 0.380284280195837\n",
      "Val  : 0.2771565427706624\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 8.3556 - val_loss: 11.9785\n",
      "Train: 0.3849110816513792\n",
      "Val  : 0.2787434818132473\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 8.2780 - val_loss: 11.9406\n",
      "Train: 0.3881503058717026\n",
      "Val  : 0.2790528986747473\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 8.2048 - val_loss: 11.9077\n",
      "Train: 0.39204067082736066\n",
      "Val  : 0.2800333337564867\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 8.1371 - val_loss: 11.8776\n",
      "Train: 0.3955736895756762\n",
      "Val  : 0.280700317928182\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 8.0710 - val_loss: 11.8483\n",
      "Train: 0.3991634176406762\n",
      "Val  : 0.28142058596651154\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 8.0090 - val_loss: 11.8194\n",
      "Train: 0.4024380296793712\n",
      "Val  : 0.2818976914622277\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 7.9489 - val_loss: 11.7898\n",
      "Train: 0.4055997725249809\n",
      "Val  : 0.2822352101264983\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.8929 - val_loss: 11.7701\n",
      "Train: 0.4093144735782264\n",
      "Val  : 0.28318578740703404\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.8391 - val_loss: 11.7433\n",
      "Train: 0.41186598963781307\n",
      "Val  : 0.2831557433091554\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.7876 - val_loss: 11.7279\n",
      "Train: 0.41606691398376816\n",
      "Val  : 0.2847788625232193\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.7389 - val_loss: 11.7060\n",
      "Train: 0.4192656427759612\n",
      "Val  : 0.2855971964004025\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.6915 - val_loss: 11.6881\n",
      "Train: 0.42203307470093215\n",
      "Val  : 0.28604082800907804\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 7.6471 - val_loss: 11.6719\n",
      "Train: 0.42481212908003285\n",
      "Val  : 0.28625032929725697\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.6056 - val_loss: 11.6497\n",
      "Train: 0.42699458848271155\n",
      "Val  : 0.2859662966334803\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 7.5642 - val_loss: 11.6362\n",
      "Train: 0.4295538996473349\n",
      "Val  : 0.28628876906228246\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 7.5251 - val_loss: 11.6289\n",
      "Train: 0.43274637677079175\n",
      "Val  : 0.2871792876080639\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.4895 - val_loss: 11.6136\n",
      "Train: 0.4355078363550045\n",
      "Val  : 0.2877208231539915\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 7.4539 - val_loss: 11.6031\n",
      "Train: 0.438894917929966\n",
      "Val  : 0.2888627844353986\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 83us/step - loss: 7.4183 - val_loss: 11.5974\n",
      "Train: 0.4413828130254855\n",
      "Val  : 0.2890842514260057\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 7.3873 - val_loss: 11.5860\n",
      "Train: 0.4440096710217555\n",
      "Val  : 0.28954280288321954\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 7.3568 - val_loss: 11.5699\n",
      "Train: 0.44584627200472665\n",
      "Val  : 0.28925121164976825\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.3266 - val_loss: 11.5577\n",
      "Train: 0.44799350921295616\n",
      "Val  : 0.28947406634799544\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 7.2971 - val_loss: 11.5492\n",
      "Train: 0.45040849934637184\n",
      "Val  : 0.2901227541517714\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 7.2704 - val_loss: 11.5421\n",
      "Train: 0.45256009949626647\n",
      "Val  : 0.29021849251226745\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 7.2444 - val_loss: 11.5325\n",
      "Train: 0.45471126865759715\n",
      "Val  : 0.2904865316902527\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 7.2186 - val_loss: 11.5274\n",
      "Train: 0.45675531814691017\n",
      "Val  : 0.29067329019062543\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.1933 - val_loss: 11.5255\n",
      "Train: 0.4590299355994751\n",
      "Val  : 0.29144443814828663\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 7.1714 - val_loss: 11.5171\n",
      "Train: 0.461225020570088\n",
      "Val  : 0.2917060214835872\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 77us/step - loss: 7.1482 - val_loss: 11.5066\n",
      "Train: 0.46226031269355483\n",
      "Val  : 0.29088097306474064\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 7.1273 - val_loss: 11.5038\n",
      "Train: 0.4645798121525552\n",
      "Val  : 0.2916167615633001\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 7.1064 - val_loss: 11.4974\n",
      "Train: 0.46676725051446377\n",
      "Val  : 0.29208166556100945\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 7.0866 - val_loss: 11.4945\n",
      "Train: 0.46857764222687526\n",
      "Val  : 0.29228640555013413\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 7.0678 - val_loss: 11.4874\n",
      "Train: 0.4704586367481029\n",
      "Val  : 0.2926422428643271\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 7.0480 - val_loss: 11.4841\n",
      "Train: 0.4720447944668144\n",
      "Val  : 0.2927350999492294\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 7.0317 - val_loss: 11.4803\n",
      "Train: 0.47376008397286073\n",
      "Val  : 0.2929109859081135\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 7.0118 - val_loss: 11.4830\n",
      "Train: 0.47611154968849345\n",
      "Val  : 0.29401181679837163\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.9963 - val_loss: 11.4765\n",
      "Train: 0.4775820184011682\n",
      "Val  : 0.2937155730127951\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.9807 - val_loss: 11.4709\n",
      "Train: 0.4784607183742048\n",
      "Val  : 0.29318933757573273\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 6.9650 - val_loss: 11.4672\n",
      "Train: 0.4800771701952783\n",
      "Val  : 0.2933822497578016\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 6.9496 - val_loss: 11.4694\n",
      "Train: 0.4818306626040203\n",
      "Val  : 0.293927017393329\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 6.9346 - val_loss: 11.4655\n",
      "Train: 0.4828007099706361\n",
      "Val  : 0.29369005136414705\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 6.9207 - val_loss: 11.4648\n",
      "Train: 0.48400822763378215\n",
      "Val  : 0.29367499106146355\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.9063 - val_loss: 11.4668\n",
      "Train: 0.4859595595854518\n",
      "Val  : 0.2944242125280239\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.8955 - val_loss: 11.4623\n",
      "Train: 0.4873840170280307\n",
      "Val  : 0.29453682254216873\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.8815 - val_loss: 11.4565\n",
      "Train: 0.4879176144992737\n",
      "Val  : 0.29385803444324743\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.8684 - val_loss: 11.4573\n",
      "Train: 0.4892888027387652\n",
      "Val  : 0.2941033365033893\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 78us/step - loss: 6.8570 - val_loss: 11.4551\n",
      "Train: 0.4907501148756974\n",
      "Val  : 0.29448490362569063\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 81us/step - loss: 6.8436 - val_loss: 11.4532\n",
      "Train: 0.4913175741917701\n",
      "Val  : 0.2938996722166607\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.8347 - val_loss: 11.4507\n",
      "Train: 0.49302750522565997\n",
      "Val  : 0.2945173816818703\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 6.8224 - val_loss: 11.4493\n",
      "Train: 0.49413365270952314\n",
      "Val  : 0.294592695248562\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 6.8122 - val_loss: 11.4490\n",
      "Train: 0.4949642459454889\n",
      "Val  : 0.2944221238497796\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.8018 - val_loss: 11.4482\n",
      "Train: 0.4964784090061967\n",
      "Val  : 0.295002741674792\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.7912 - val_loss: 11.4481\n",
      "Train: 0.4976115872082279\n",
      "Val  : 0.2951743223203156\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.7816 - val_loss: 11.4478\n",
      "Train: 0.49855052703292513\n",
      "Val  : 0.2950435151599271\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.7746 - val_loss: 11.4464\n",
      "Train: 0.4995017945225246\n",
      "Val  : 0.2949571216954156\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.7633 - val_loss: 11.4413\n",
      "Train: 0.4998249615541516\n",
      "Val  : 0.2942812366266707\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.7550 - val_loss: 11.4392\n",
      "Train: 0.5008849328345962\n",
      "Val  : 0.294508052340217\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.7450 - val_loss: 11.4431\n",
      "Train: 0.50189680036526\n",
      "Val  : 0.29467082678232626\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.7374 - val_loss: 11.4419\n",
      "Train: 0.5026620282324229\n",
      "Val  : 0.2946377379758772\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.7295 - val_loss: 11.4405\n",
      "Train: 0.5035042805544588\n",
      "Val  : 0.2944907750528996\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 6.7197 - val_loss: 11.4449\n",
      "Train: 0.5044479250208365\n",
      "Val  : 0.2948184188752374\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 70us/step - loss: 6.7128 - val_loss: 11.4469\n",
      "Train: 0.5056370688207711\n",
      "Val  : 0.2952889858866859\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.7062 - val_loss: 11.4406\n",
      "Train: 0.5060985820410618\n",
      "Val  : 0.2947967646285414\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 72us/step - loss: 6.6971 - val_loss: 11.4384\n",
      "Train: 0.5066234674480009\n",
      "Val  : 0.29454200495794486\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.6906 - val_loss: 11.4389\n",
      "Train: 0.5075837709293424\n",
      "Val  : 0.29463697182598303\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.6826 - val_loss: 11.4459\n",
      "Train: 0.5086822439218427\n",
      "Val  : 0.295233163950199\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.6758 - val_loss: 11.4438\n",
      "Train: 0.5090567985801017\n",
      "Val  : 0.29467165395337763\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.6700 - val_loss: 11.4417\n",
      "Train: 0.5097584128486353\n",
      "Val  : 0.2947770515704919\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.6627 - val_loss: 11.4457\n",
      "Train: 0.5112927493729594\n",
      "Val  : 0.29582203212415603\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.6575 - val_loss: 11.4385\n",
      "Train: 0.5110512887603978\n",
      "Val  : 0.294664281460918\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 80us/step - loss: 6.6495 - val_loss: 11.4465\n",
      "Train: 0.5122510009788077\n",
      "Val  : 0.29538347842850243\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 82us/step - loss: 6.6441 - val_loss: 11.4390\n",
      "Train: 0.5122843445616069\n",
      "Val  : 0.2945918822281715\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.6379 - val_loss: 11.4369\n",
      "Train: 0.5130623687075916\n",
      "Val  : 0.2946055595458547\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.6325 - val_loss: 11.4367\n",
      "Train: 0.5135153901419591\n",
      "Val  : 0.29433799417804596\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 6.6262 - val_loss: 11.4350\n",
      "Train: 0.5141787865201732\n",
      "Val  : 0.2943911808275817\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.6199 - val_loss: 11.4351\n",
      "Train: 0.5146937842622691\n",
      "Val  : 0.29420007764415024\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.6146 - val_loss: 11.4384\n",
      "Train: 0.51550042475736\n",
      "Val  : 0.2945607417584328\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 6.6092 - val_loss: 11.4414\n",
      "Train: 0.5153406248182493\n",
      "Val  : 0.2938760572537188\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 79us/step - loss: 6.6048 - val_loss: 11.4351\n",
      "Train: 0.5160765640328125\n",
      "Val  : 0.29390950852310366\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5984 - val_loss: 11.4434\n",
      "Train: 0.5175879148098378\n",
      "Val  : 0.295187011993808\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.5950 - val_loss: 11.4365\n",
      "Train: 0.5170363068922037\n",
      "Val  : 0.29383421705513524\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.5899 - val_loss: 11.4396\n",
      "Train: 0.5182790121534706\n",
      "Val  : 0.29460289913327625\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.5839 - val_loss: 11.4445\n",
      "Train: 0.5189040118611977\n",
      "Val  : 0.2949003409227583\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.5804 - val_loss: 11.4365\n",
      "Train: 0.5186694842583062\n",
      "Val  : 0.2937837508936318\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.5763 - val_loss: 11.4383\n",
      "Train: 0.5194791787272145\n",
      "Val  : 0.2941346451490707\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.5721 - val_loss: 11.4393\n",
      "Train: 0.5201587839091295\n",
      "Val  : 0.2942817737588041\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5663 - val_loss: 11.4384\n",
      "Train: 0.5208727837479175\n",
      "Val  : 0.29451469224307875\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5626 - val_loss: 11.4358\n",
      "Train: 0.5209323509761519\n",
      "Val  : 0.2940687215852832\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5574 - val_loss: 11.4365\n",
      "Train: 0.5210579588508512\n",
      "Val  : 0.29380663956666836\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 76us/step - loss: 6.5534 - val_loss: 11.4342\n",
      "Train: 0.5217782238350657\n",
      "Val  : 0.2941938834224906\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.5503 - val_loss: 11.4303\n",
      "Train: 0.5220790014928963\n",
      "Val  : 0.293982321244646\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.5465 - val_loss: 11.4278\n",
      "Train: 0.5223849663280999\n",
      "Val  : 0.2937336654268256\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5421 - val_loss: 11.4325\n",
      "Train: 0.5226334042470248\n",
      "Val  : 0.293500615751818\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 74us/step - loss: 6.5379 - val_loss: 11.4345\n",
      "Train: 0.5231228178075062\n",
      "Val  : 0.2936814919327665\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 73us/step - loss: 6.5339 - val_loss: 11.4351\n",
      "Train: 0.523034671275187\n",
      "Val  : 0.29323092654720323\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 75us/step - loss: 6.5320 - val_loss: 11.4307\n",
      "Train: 0.5232639028212275\n",
      "Val  : 0.2927882209081335\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      "4220/4220 [==============================] - 0s 71us/step - loss: 6.5270 - val_loss: 11.4357\n",
      "Train: 0.5239771804602328\n",
      "Val  : 0.29331770239286853\n",
      "\n",
      "Train on 4220 samples, validate on 1055 samples\n",
      "Epoch 1/1\n",
      " 768/4220 [====>.........................] - ETA: 0s - loss: 6.6607"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-dcd71fc5e506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m     tuner.fit([U_train, V_train], y_train, \n\u001b[1;32m     40\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mU_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0meval_tuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m    117\u001b[0m            (delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1)):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3334\u001b[0m     \"\"\"\n\u001b[1;32m   3335\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3336\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3248\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3250\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3251\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3388\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1586\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m         \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SHARED WEIGHTS + WEIGHT REGULARIZATION!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "shared = Dense(d, activation='linear',\n",
    "               kernel_regularizer=keras.regularizers.l2(0.0001))\n",
    "\n",
    "u_w = shared(u_input)\n",
    "v_w = shared(v_input)\n",
    "\n",
    "w = keras.layers.add([u_w, v_w])\n",
    "\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.15193617681553176\n",
      "Val  : 0.11672301506413547\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 1s 262us/step - loss: 22.2630 - val_loss: 21.9162\n",
      "Train: 0.33543496615001767\n",
      "Val  : 0.28270333888354926\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 22.0163 - val_loss: 21.7455\n",
      "Train: 0.34175537606164114\n",
      "Val  : 0.28645207037499826\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 21.7657 - val_loss: 21.5747\n",
      "Train: 0.34386137309560016\n",
      "Val  : 0.287532890057162\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 21.5189 - val_loss: 21.4069\n",
      "Train: 0.3447440385585991\n",
      "Val  : 0.28764349234387915\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 21.2759 - val_loss: 21.2422\n",
      "Train: 0.345623023719111\n",
      "Val  : 0.2882507872525929\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 21.0396 - val_loss: 21.0812\n",
      "Train: 0.34623080681504187\n",
      "Val  : 0.2884373632503174\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 20.8093 - val_loss: 20.9247\n",
      "Train: 0.3468922092482544\n",
      "Val  : 0.2887774357858243\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 20.5835 - val_loss: 20.7707\n",
      "Train: 0.3473580316929571\n",
      "Val  : 0.2888869369088582\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 20.3638 - val_loss: 20.6204\n",
      "Train: 0.3478706216907087\n",
      "Val  : 0.2891348663477559\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 20.1485 - val_loss: 20.4720\n",
      "Train: 0.34835493318503763\n",
      "Val  : 0.28930916252611405\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 19.9379 - val_loss: 20.3283\n",
      "Train: 0.3488613370380659\n",
      "Val  : 0.2894533656543001\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 19.7327 - val_loss: 20.1870\n",
      "Train: 0.3493898033830197\n",
      "Val  : 0.28978082698591495\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 19.5322 - val_loss: 20.0500\n",
      "Train: 0.3498790880113972\n",
      "Val  : 0.2899978537593745\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 19.3366 - val_loss: 19.9152\n",
      "Train: 0.3503391474299934\n",
      "Val  : 0.29023538226634454\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 64us/step - loss: 19.1455 - val_loss: 19.7841\n",
      "Train: 0.35085823034314767\n",
      "Val  : 0.2904521463111994\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 18.9593 - val_loss: 19.6558\n",
      "Train: 0.3513996667046059\n",
      "Val  : 0.29066598100396507\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 18.7777 - val_loss: 19.5303\n",
      "Train: 0.35193937277377685\n",
      "Val  : 0.2908751244019639\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 18.6001 - val_loss: 19.4080\n",
      "Train: 0.3524541765601669\n",
      "Val  : 0.29106720199980324\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 18.4265 - val_loss: 19.2882\n",
      "Train: 0.3529895151653864\n",
      "Val  : 0.2913008564046585\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 18.2567 - val_loss: 19.1712\n",
      "Train: 0.35350346811378874\n",
      "Val  : 0.29154339262172163\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 18.0914 - val_loss: 19.0569\n",
      "Train: 0.3540420844127397\n",
      "Val  : 0.29175939102591003\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 17.9299 - val_loss: 18.9450\n",
      "Train: 0.3545715102174513\n",
      "Val  : 0.2919807078681893\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 17.7720 - val_loss: 18.8355\n",
      "Train: 0.3550985087148945\n",
      "Val  : 0.2922084792822737\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 17.6173 - val_loss: 18.7285\n",
      "Train: 0.35564715676052006\n",
      "Val  : 0.2924160745492797\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 17.4656 - val_loss: 18.6233\n",
      "Train: 0.35618814974989293\n",
      "Val  : 0.29260753873078255\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 17.3175 - val_loss: 18.5210\n",
      "Train: 0.3567398944520976\n",
      "Val  : 0.29279459360936744\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 17.1727 - val_loss: 18.4204\n",
      "Train: 0.357291930316502\n",
      "Val  : 0.29297869895844336\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 17.0307 - val_loss: 18.3219\n",
      "Train: 0.3578444870098217\n",
      "Val  : 0.29317481847676274\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 16.8920 - val_loss: 18.2255\n",
      "Train: 0.358396356144632\n",
      "Val  : 0.2933848191895112\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 16.7557 - val_loss: 18.1309\n",
      "Train: 0.3589585098881364\n",
      "Val  : 0.29356436479811726\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 16.6223 - val_loss: 18.0384\n",
      "Train: 0.3595225847056221\n",
      "Val  : 0.29378295204088595\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 16.4914 - val_loss: 17.9478\n",
      "Train: 0.36007129093779505\n",
      "Val  : 0.2939391443600915\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 16.3631 - val_loss: 17.8587\n",
      "Train: 0.36064814189478067\n",
      "Val  : 0.2941482069006656\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 16.2373 - val_loss: 17.7715\n",
      "Train: 0.36120639059323373\n",
      "Val  : 0.29432014503166637\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 16.1136 - val_loss: 17.6856\n",
      "Train: 0.36177884851930076\n",
      "Val  : 0.2945019395674415\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 15.9921 - val_loss: 17.6013\n",
      "Train: 0.36232199049060526\n",
      "Val  : 0.2946457600072934\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 15.8725 - val_loss: 17.5186\n",
      "Train: 0.36286687531071854\n",
      "Val  : 0.2948085883647795\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 15.7551 - val_loss: 17.4373\n",
      "Train: 0.3634282053798186\n",
      "Val  : 0.2949247923961829\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 15.6394 - val_loss: 17.3569\n",
      "Train: 0.36398195515749726\n",
      "Val  : 0.29509563539549966\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 15.5257 - val_loss: 17.2783\n",
      "Train: 0.3645120528955792\n",
      "Val  : 0.2952359132357145\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 64us/step - loss: 15.4137 - val_loss: 17.2011\n",
      "Train: 0.3650634056253586\n",
      "Val  : 0.2953454443036195\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 15.3035 - val_loss: 17.1247\n",
      "Train: 0.3656194040717182\n",
      "Val  : 0.29549249270919153\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 15.1949 - val_loss: 17.0498\n",
      "Train: 0.3661569621631739\n",
      "Val  : 0.2955980730933825\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 15.0881 - val_loss: 16.9761\n",
      "Train: 0.36669241435697475\n",
      "Val  : 0.29571890678696516\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 14.9829 - val_loss: 16.9037\n",
      "Train: 0.36723665614318945\n",
      "Val  : 0.29582823017299475\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 14.8791 - val_loss: 16.8319\n",
      "Train: 0.3677636989372188\n",
      "Val  : 0.2959511900394915\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 14.7767 - val_loss: 16.7615\n",
      "Train: 0.36827839405165824\n",
      "Val  : 0.296026250107449\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 14.6758 - val_loss: 16.6921\n",
      "Train: 0.36880127134083623\n",
      "Val  : 0.2961369846010935\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 14.5764 - val_loss: 16.6234\n",
      "Train: 0.3693254924083496\n",
      "Val  : 0.29620485010672265\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 14.4784 - val_loss: 16.5558\n",
      "Train: 0.3698373019698864\n",
      "Val  : 0.2963074244534607\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 14.3814 - val_loss: 16.4890\n",
      "Train: 0.37035192707803644\n",
      "Val  : 0.2964253465575125\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 14.2859 - val_loss: 16.4232\n",
      "Train: 0.37086425499727316\n",
      "Val  : 0.2965129904026205\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 14.1913 - val_loss: 16.3582\n",
      "Train: 0.371371797742663\n",
      "Val  : 0.2965633104147109\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 14.0980 - val_loss: 16.2941\n",
      "Train: 0.37186965397614313\n",
      "Val  : 0.2966346600315124\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 14.0055 - val_loss: 16.2303\n",
      "Train: 0.37236957698166956\n",
      "Val  : 0.2966633085092374\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 13.9145 - val_loss: 16.1679\n",
      "Train: 0.37285817112126063\n",
      "Val  : 0.29676622770849226\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 13.8245 - val_loss: 16.1063\n",
      "Train: 0.37333275973393787\n",
      "Val  : 0.29677614119822954\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 13.7357 - val_loss: 16.0450\n",
      "Train: 0.37380656821621444\n",
      "Val  : 0.29682231256344316\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 13.6478 - val_loss: 15.9846\n",
      "Train: 0.37429049185448404\n",
      "Val  : 0.2968663693557165\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 13.5609 - val_loss: 15.9253\n",
      "Train: 0.3747496080456618\n",
      "Val  : 0.2969098528962515\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 13.4751 - val_loss: 15.8662\n",
      "Train: 0.3752010593750764\n",
      "Val  : 0.2969452882570058\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 13.3901 - val_loss: 15.8079\n",
      "Train: 0.3756650245048775\n",
      "Val  : 0.29697074950421243\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 13.3060 - val_loss: 15.7504\n",
      "Train: 0.37612830733944247\n",
      "Val  : 0.2970101849967071\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 13.2230 - val_loss: 15.6935\n",
      "Train: 0.3765780375678342\n",
      "Val  : 0.29706209258444743\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 13.1407 - val_loss: 15.6371\n",
      "Train: 0.37702365496294354\n",
      "Val  : 0.2970970075063218\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 13.0594 - val_loss: 15.5815\n",
      "Train: 0.37746553962007134\n",
      "Val  : 0.2970732623765286\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 12.9789 - val_loss: 15.5263\n",
      "Train: 0.37790843466356605\n",
      "Val  : 0.2970798552068249\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 12.8993 - val_loss: 15.4716\n",
      "Train: 0.3783285361656401\n",
      "Val  : 0.29709874960854443\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 12.8203 - val_loss: 15.4172\n",
      "Train: 0.37875993678024916\n",
      "Val  : 0.2971192898299928\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 12.7423 - val_loss: 15.3642\n",
      "Train: 0.3791910193998519\n",
      "Val  : 0.29715506951999554\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 12.6654 - val_loss: 15.3111\n",
      "Train: 0.3796132904622621\n",
      "Val  : 0.29715832599208514\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 12.5889 - val_loss: 15.2589\n",
      "Train: 0.3800385835283986\n",
      "Val  : 0.29718775137354114\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 12.5134 - val_loss: 15.2071\n",
      "Train: 0.3804487354375651\n",
      "Val  : 0.29720000313149786\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 12.4386 - val_loss: 15.1555\n",
      "Train: 0.38086247779463395\n",
      "Val  : 0.29720781012725606\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 12.3644 - val_loss: 15.1044\n",
      "Train: 0.3812647819314997\n",
      "Val  : 0.2972038600320669\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 12.2911 - val_loss: 15.0544\n",
      "Train: 0.38166637274885146\n",
      "Val  : 0.29719646843603775\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 12.2183 - val_loss: 15.0042\n",
      "Train: 0.38206764202625226\n",
      "Val  : 0.29720944218000367\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 12.1465 - val_loss: 14.9547\n",
      "Train: 0.38245758085273346\n",
      "Val  : 0.29718991668163686\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 12.0751 - val_loss: 14.9056\n",
      "Train: 0.38285469752283446\n",
      "Val  : 0.297155015055254\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4955 [==============================] - 0s 73us/step - loss: 12.0045 - val_loss: 14.8571\n",
      "Train: 0.38323736581430934\n",
      "Val  : 0.2971452545673046\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 11.9348 - val_loss: 14.8089\n",
      "Train: 0.3836181120841838\n",
      "Val  : 0.2971243946568426\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 11.8656 - val_loss: 14.7615\n",
      "Train: 0.38400283102979016\n",
      "Val  : 0.2971331554246178\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 11.7970 - val_loss: 14.7145\n",
      "Train: 0.38438730320801445\n",
      "Val  : 0.2971318170066904\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 11.7292 - val_loss: 14.6677\n",
      "Train: 0.3847661585267367\n",
      "Val  : 0.29709056959384555\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 11.6620 - val_loss: 14.6213\n",
      "Train: 0.3851435387282343\n",
      "Val  : 0.2970902831372456\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 11.5951 - val_loss: 14.5753\n",
      "Train: 0.3855207646021687\n",
      "Val  : 0.2970759854644459\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 11.5292 - val_loss: 14.5300\n",
      "Train: 0.3858939897561367\n",
      "Val  : 0.2970252411876794\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 11.4637 - val_loss: 14.4848\n",
      "Train: 0.38627414190976267\n",
      "Val  : 0.2970225619683971\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 11.3987 - val_loss: 14.4399\n",
      "Train: 0.38664145588572413\n",
      "Val  : 0.29701791802352984\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 11.3343 - val_loss: 14.3954\n",
      "Train: 0.38701963556421326\n",
      "Val  : 0.29701804053343983\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 11.2705 - val_loss: 14.3516\n",
      "Train: 0.38737758520477383\n",
      "Val  : 0.29698104103290623\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 11.2074 - val_loss: 14.3077\n",
      "Train: 0.38775598566651304\n",
      "Val  : 0.2969558091397575\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 11.1447 - val_loss: 14.2646\n",
      "Train: 0.38814041572439295\n",
      "Val  : 0.29693925721233816\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 11.0827 - val_loss: 14.2216\n",
      "Train: 0.38850502276306487\n",
      "Val  : 0.29690192304162527\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 11.0213 - val_loss: 14.1792\n",
      "Train: 0.3888800870973646\n",
      "Val  : 0.29688888561321986\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 76us/step - loss: 10.9601 - val_loss: 14.1372\n",
      "Train: 0.3892436127085536\n",
      "Val  : 0.2968511680934717\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 10.8998 - val_loss: 14.0953\n",
      "Train: 0.3896180966703102\n",
      "Val  : 0.2968193332961494\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      " 928/4955 [====>.........................] - ETA: 0s - loss: 10.7741"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-0a0d3eb3c1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m     tuner.fit([U_train, V_train], y_train, \n\u001b[1;32m     34\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mU_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m               verbose=1)\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0meval_tuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RELU INSTEAD OF SQUARE W!!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='relu')(diff_vecs)\n",
    "\n",
    "u_mult_w = multiply([u_input, w])\n",
    "\n",
    "final_dot = dot([u_mult_w, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(60):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.15936289944840984\n",
      "Val  : 0.11936493267517119\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 1s 191us/step - loss: 20.9909 - val_loss: 20.2568\n",
      "Train: 0.2775347820766862\n",
      "Val  : 0.2454452280400833\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 77us/step - loss: 19.1798 - val_loss: 18.3885\n",
      "Train: 0.3313178703140733\n",
      "Val  : 0.2925014193842448\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 79us/step - loss: 17.4387 - val_loss: 17.5239\n",
      "Train: 0.3370596660298611\n",
      "Val  : 0.2972243421553206\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 74us/step - loss: 16.4582 - val_loss: 16.8650\n",
      "Train: 0.34588803495475795\n",
      "Val  : 0.3098683208863316\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 15.5529 - val_loss: 16.2671\n",
      "Train: 0.35205099710316917\n",
      "Val  : 0.316401117724531\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 14.6359 - val_loss: 15.5519\n",
      "Train: 0.36132094106733814\n",
      "Val  : 0.32719833908755613\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 13.6274 - val_loss: 14.8953\n",
      "Train: 0.37595288483994177\n",
      "Val  : 0.33384361914911126\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 12.5848 - val_loss: 14.2051\n",
      "Train: 0.38059603569414124\n",
      "Val  : 0.3320735576006322\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 11.5143 - val_loss: 13.5393\n",
      "Train: 0.3884392281973419\n",
      "Val  : 0.32985725590499965\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 64us/step - loss: 10.4961 - val_loss: 12.8414\n",
      "Train: 0.3946521433660457\n",
      "Val  : 0.3254829960683427\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 9.5514 - val_loss: 12.1500\n",
      "Train: 0.4032471586061557\n",
      "Val  : 0.32632465045225845\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 8.6997 - val_loss: 11.5573\n",
      "Train: 0.4178187988563865\n",
      "Val  : 0.33100219812709564\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 7.9037 - val_loss: 10.9691\n",
      "Train: 0.42772464921251474\n",
      "Val  : 0.3317328039433214\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 7.1953 - val_loss: 10.4265\n",
      "Train: 0.4450136710461373\n",
      "Val  : 0.3341272065149513\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 6.5369 - val_loss: 10.0570\n",
      "Train: 0.45476802569074753\n",
      "Val  : 0.33021282324656814\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 5.9446 - val_loss: 9.6869\n",
      "Train: 0.46924184196853413\n",
      "Val  : 0.3276179299209463\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 5.3990 - val_loss: 9.4113\n",
      "Train: 0.4886420596845127\n",
      "Val  : 0.32706932996939525\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 64us/step - loss: 4.8966 - val_loss: 9.1726\n",
      "Train: 0.5047996352010314\n",
      "Val  : 0.3237003138853471\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 4.4434 - val_loss: 8.9714\n",
      "Train: 0.5272964639838197\n",
      "Val  : 0.32481430016592094\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 4.0320 - val_loss: 8.8627\n",
      "Train: 0.5469903445442895\n",
      "Val  : 0.32169499481036656\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 3.6534 - val_loss: 8.6821\n",
      "Train: 0.567889822300248\n",
      "Val  : 0.3205073023473897\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 3.3190 - val_loss: 8.6633\n",
      "Train: 0.5873011739464052\n",
      "Val  : 0.3154286109194939\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 3.0104 - val_loss: 8.5849\n",
      "Train: 0.6099957016381433\n",
      "Val  : 0.31521921995743535\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 2.7287 - val_loss: 8.5608\n",
      "Train: 0.6309313807104415\n",
      "Val  : 0.3092958754044408\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 2.4738 - val_loss: 8.5651\n",
      "Train: 0.6537360603634741\n",
      "Val  : 0.30865899270170977\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 2.2393 - val_loss: 8.6179\n",
      "Train: 0.6760515064630384\n",
      "Val  : 0.307008046394687\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 2.0226 - val_loss: 8.6763\n",
      "Train: 0.6945824923728393\n",
      "Val  : 0.3046713776365586\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 1.8250 - val_loss: 8.7615\n",
      "Train: 0.7176148852123402\n",
      "Val  : 0.3047833955369066\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 1.6474 - val_loss: 8.7864\n",
      "Train: 0.7377199568766344\n",
      "Val  : 0.2985705825745635\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 1.4867 - val_loss: 8.9127\n",
      "Train: 0.7550406505847735\n",
      "Val  : 0.2957771482777281\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 1.3400 - val_loss: 8.9754\n",
      "Train: 0.7757088797151691\n",
      "Val  : 0.29334944888205655\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 1.2069 - val_loss: 9.1686\n",
      "Train: 0.791188323505374\n",
      "Val  : 0.288423801879018\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 71us/step - loss: 1.0876 - val_loss: 9.2587\n",
      "Train: 0.8078615004880977\n",
      "Val  : 0.2826657446015529\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 65us/step - loss: 0.9826 - val_loss: 9.4231\n",
      "Train: 0.8234242069920051\n",
      "Val  : 0.28094534211473193\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 0.8866 - val_loss: 9.4429\n",
      "Train: 0.8393188070785449\n",
      "Val  : 0.2780543540946509\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 0.7994 - val_loss: 9.6345\n",
      "Train: 0.8516767068844193\n",
      "Val  : 0.2806350642397315\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 0.7254 - val_loss: 9.8617\n",
      "Train: 0.8641612433978856\n",
      "Val  : 0.2741119202530217\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 0.6565 - val_loss: 9.9298\n",
      "Train: 0.8743093148358126\n",
      "Val  : 0.26681887074868593\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 70us/step - loss: 0.5963 - val_loss: 10.1146\n",
      "Train: 0.8847717428196973\n",
      "Val  : 0.2691754414793261\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 67us/step - loss: 0.5427 - val_loss: 10.2492\n",
      "Train: 0.8935460532546914\n",
      "Val  : 0.2674644125625601\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4955 [==============================] - 0s 66us/step - loss: 0.4949 - val_loss: 10.3526\n",
      "Train: 0.9008007829993092\n",
      "Val  : 0.26189858462501026\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 72us/step - loss: 0.4558 - val_loss: 10.6626\n",
      "Train: 0.9075652721380131\n",
      "Val  : 0.2633414757433929\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 0.4182 - val_loss: 10.7530\n",
      "Train: 0.9128917240901747\n",
      "Val  : 0.25625029426216367\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 0.3884 - val_loss: 10.8447\n",
      "Train: 0.9171063779581328\n",
      "Val  : 0.2562239232791004\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 0.3628 - val_loss: 11.0253\n",
      "Train: 0.9210725786633951\n",
      "Val  : 0.2521754158344972\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 0.3427 - val_loss: 11.1157\n",
      "Train: 0.9253161992505133\n",
      "Val  : 0.2525208024043792\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 66us/step - loss: 0.3201 - val_loss: 11.2351\n",
      "Train: 0.9290605791876332\n",
      "Val  : 0.2532804642244092\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 73us/step - loss: 0.3067 - val_loss: 11.3340\n",
      "Train: 0.9310639534362563\n",
      "Val  : 0.25250323347169845\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 68us/step - loss: 0.2915 - val_loss: 11.4157\n",
      "Train: 0.933064452027728\n",
      "Val  : 0.24769085494229093\n",
      "\n",
      "Train on 4955 samples, validate on 1239 samples\n",
      "Epoch 1/1\n",
      "4955/4955 [==============================] - 0s 69us/step - loss: 0.2791 - val_loss: 11.3635\n",
      "Train: 0.9350345370713963\n",
      "Val  : 0.24885307741433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRY BOTTLENECK!!\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import concatenate, multiply, dot\n",
    "from keras.models import Model\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "bottleneck = Dense(150, activation='linear')(diff_vecs)\n",
    "w = Dense(d, activation='linear')(bottleneck)\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(50):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
