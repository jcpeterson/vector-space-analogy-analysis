{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, copy\n",
    "from joblib import Parallel, delayed\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from scipy.stats import pearsonr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fns_and_meta(data_pth, folders):\n",
    "    \"\"\" load the word vector model filenames\n",
    "    \"\"\"\n",
    "    models_meta = {}\n",
    "    for folder in folders:\n",
    "        for file in os.listdir(os.path.join(data_pth, \n",
    "                                            folder)):\n",
    "            model_meta = {}\n",
    "            model_meta['root'] = data_pth\n",
    "            model_meta['class'] = folder\n",
    "            model_meta['fn'] = file\n",
    "            #model_meta['name'] = file[:-4]\n",
    "            \n",
    "            if folder == 'glove':\n",
    "                dim = file[file.find('B')+2:file.find('d')]\n",
    "                model_meta['d'] = int(dim)\n",
    "            elif folder == 'w2v':\n",
    "                model_meta['d'] = 300\n",
    "            \n",
    "            models_meta[file[:-4]] = model_meta\n",
    "    \n",
    "    return models_meta\n",
    "\n",
    "def load_relsim_data(path='', fn='relsim_mean_ratings.csv'):\n",
    "\n",
    "    df = pd.read_csv(path+fn)\n",
    "    df['rel1_type'] = df['relation1'].apply(lambda x: int(x[:-1]))\n",
    "    df['rel2_type'] = df['relation2'].apply(lambda x: int(x[:-1]))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def load_asym_data(path='../symmetry/', \n",
    "                   fn='symmetry_mean_ratings.csv',\n",
    "                   mode='like_rel_sim'):\n",
    "    \n",
    "    df = pd.read_csv(path+fn)\n",
    "    df['rel1_type'] = df['relation1'].apply(lambda x: int(x[:-1]))\n",
    "    df['rel2_type'] = df['relation2'].apply(lambda x: int(x[:-1]))\n",
    "    \n",
    "    if mode == 'like_rel_sim':\n",
    "        print(\"Loading asymmetry data in relsim style.\\n\"+\n",
    "              \"Use mode='orig' for the standard format.\")\n",
    "        \n",
    "        df_like_rel_sim = []\n",
    "        for row in df.iterrows():\n",
    "            \n",
    "            fwd_row = copy.deepcopy(dict(row[1]))\n",
    "            bkw_row = copy.deepcopy(dict(row[1]))\n",
    "            \n",
    "            fwd_row['mean_rating'] = fwd_row.pop('forward_rating')\n",
    "            fwd_row['num_ratings'] = fwd_row.pop('forward_n')\n",
    "            fwd_row.pop('backward_rating')\n",
    "            fwd_row.pop('backward_n')\n",
    "            \n",
    "            bkw_row['mean_rating'] = bkw_row.pop('backward_rating')\n",
    "            bkw_row['num_ratings'] = bkw_row.pop('backward_n')\n",
    "            bkw_row.pop('forward_rating')\n",
    "            bkw_row.pop('forward_n')\n",
    "            \n",
    "            bkw_row['pair1_word1'] = copy.deepcopy(fwd_row['pair2_word1'])\n",
    "            bkw_row['pair1_word2'] = copy.deepcopy(fwd_row['pair2_word2'])\n",
    "            bkw_row['pair2_word1'] = copy.deepcopy(fwd_row['pair1_word1'])\n",
    "            bkw_row['pair2_word2'] = copy.deepcopy(fwd_row['pair1_word2'])\n",
    "            \n",
    "            fwd_row['direction'] = 'forward'\n",
    "            bkw_row['direction'] = 'backward'\n",
    "            \n",
    "            df_like_rel_sim.append(fwd_row)\n",
    "            df_like_rel_sim.append(bkw_row)\n",
    "            \n",
    "        return pd.DataFrame(df_like_rel_sim)\n",
    "    else:\n",
    "        return df\n",
    "\n",
    "def words_in_vocab(words, model):\n",
    "    \n",
    "    status = True\n",
    "    for w in words:\n",
    "        try:\n",
    "            if w not in model.vocab:\n",
    "                status = False\n",
    "        except:\n",
    "            if w not in model.keys():\n",
    "                status = False            \n",
    "    return status\n",
    "\n",
    "\n",
    "def compute_similarity(u, v, metric='e'):\n",
    "    \n",
    "    if metric in ['inner product', 'ip']:\n",
    "        return np.dot(u, v)\n",
    "    \n",
    "    elif metric in ['cosine', 'c']:\n",
    "        return 1 - cosine(u, v)\n",
    "    \n",
    "    elif metric in ['euclidean', 'e']:\n",
    "        return -euclidean(u, v)\n",
    "    \n",
    "    elif metric in ['dawn_euclidean', 'd']:\n",
    "        return 1 - euclidean(u, v)\n",
    "\n",
    "    \n",
    "def get_analogy_words(trial):\n",
    "    \n",
    "    return [trial.pair1_word1,\n",
    "            trial.pair1_word2,\n",
    "            trial.pair2_word1,\n",
    "            trial.pair2_word2]\n",
    "\n",
    "\n",
    "def get_relsim_vocab(df):\n",
    "    \n",
    "    words = []\n",
    "    words += list(df.pair1_word1.unique())\n",
    "    words += list(df.pair1_word2.unique())\n",
    "    words += list(df.pair2_word1.unique())\n",
    "    words += list(df.pair2_word2.unique())\n",
    "    \n",
    "    return list(set(words))\n",
    "\n",
    "\n",
    "def create_condensed_model_relsim(df, model):\n",
    "    \"\"\" Create a condensed model made just\n",
    "        for the relational similarity data.\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab = get_relsim_vocab(df)\n",
    "    \n",
    "    return create_condensed_model(vocab, model)\n",
    "\n",
    "\n",
    "def create_condensed_model(vocab, model):\n",
    "    \"\"\" Create a condensed model as a {word: vector} \n",
    "        dictionary object for a smaller vocabulary\n",
    "        from an input w2v gensim model.\n",
    "    \"\"\"\n",
    "    condensed_model = {}\n",
    "    \n",
    "    for word in vocab:\n",
    "        if word in model.vocab:\n",
    "            condensed_model[word] = model[word]\n",
    "        \n",
    "    return condensed_model\n",
    "\n",
    "\n",
    "def load_model(model_fn='GoogleNews-vectors-negative300.bin',\n",
    "               data_pth = '../../../../datasets/word-vector-datasets/',\n",
    "               binary=True, load_condensed_stem=None, \n",
    "               condensed_vocab=None, save_condensed=False, \n",
    "               condensed_path=None):\n",
    "    \n",
    "    \"\"\" load word vector model w/ gensim\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'glove' in model_fn:\n",
    "        binary = False\n",
    "        data_pth += 'glove/'\n",
    "    elif 'GoogleNews' in model_fn:\n",
    "        data_pth += 'w2v/'\n",
    "        \n",
    "    if None not in [load_condensed_stem, condensed_vocab, condensed_path]:\n",
    "        c_model_fn = model_fn[:-3] + load_condensed_stem\n",
    "        c_model_path = condensed_path + c_model_fn\n",
    "        \n",
    "        if os.path.isfile(c_model_path):\n",
    "            return pickle.load(open(c_model_path, \"rb\"))\n",
    "        else:\n",
    "            print('No condensed models found. Creating now...')\n",
    "            model = KeyedVectors.load_word2vec_format(data_pth + model_fn, \n",
    "                                                      binary=binary)\n",
    "            c_model = create_condensed_model(condensed_vocab, model)\n",
    "            if save_condensed: pickle.dump(c_model, open(c_model_path, \"wb\"))\n",
    "            return c_model\n",
    "    else:\n",
    "        print('Loading uncondensed model...')\n",
    "        return KeyedVectors.load_word2vec_format(data_pth + model_fn, \n",
    "                                                 binary=binary)\n",
    "\n",
    "\n",
    "# def makesave_or_load_condensed(models_meta, vocab, \n",
    "#                                load_condensed_stem=''):\n",
    "    \n",
    "#     # store all condensed models in one dict 'models'\n",
    "#     models = copy.deepcopy(models_meta)\n",
    "    \n",
    "#     for model_key in models_meta.keys():\n",
    "\n",
    "#         models[model_key]['model'] = load_model(model_fn=models[model_key]['fn'],\n",
    "#                data_pth=models[model_key]['root'],\n",
    "#                binary=True, load_condensed_stem='relsim.condensed.p', \n",
    "#                condensed_vocab=vocab, save_condensed=True, \n",
    "#                condensed_path='condensed_models/')\n",
    "        \n",
    "#     return models\n",
    "def makesave_or_load_condensed(models_meta, vocab, \n",
    "                               load_condensed_stem='condensed.p'):\n",
    "    \n",
    "    # store all condensed models in one dict 'models'\n",
    "    models = copy.deepcopy(models_meta)\n",
    "    \n",
    "    for model_key in models_meta.keys():\n",
    "\n",
    "        models[model_key]['model'] = load_model(model_fn=models[model_key]['fn'],\n",
    "               data_pth=models[model_key]['root'],\n",
    "               binary=True, load_condensed_stem=load_condensed_stem, \n",
    "               condensed_vocab=vocab, save_condensed=True, \n",
    "               condensed_path='condensed_models/')\n",
    "        \n",
    "    return models\n",
    "\n",
    "\n",
    "def get_word_vector(word, model, normalize=True):\n",
    "    \n",
    "    word_vector = model[word]\n",
    "    \n",
    "    if normalize:\n",
    "        return word_vector / norm(word_vector)\n",
    "    else:       \n",
    "        return word_vector\n",
    "\n",
    "\n",
    "def get_diff_vecs(words, model, dims=None):\n",
    "    \n",
    "    w1_vec = get_word_vector(words[0], model)\n",
    "    w2_vec = get_word_vector(words[1], model)\n",
    "    w3_vec = get_word_vector(words[2], model)\n",
    "    w4_vec = get_word_vector(words[3], model)\n",
    "    \n",
    "    diff_pair1 = w1_vec - w2_vec\n",
    "    diff_pair2 = w3_vec - w4_vec\n",
    "    \n",
    "    if dims is None:\n",
    "        return diff_pair1, diff_pair2\n",
    "    else:\n",
    "        return diff_pair1[dims], diff_pair2[dims]\n",
    "    \n",
    "\n",
    "def naive_train_val_split(df, val_percent=0.2, \n",
    "                           shuffle=True, seed=1):\n",
    "    \"\"\" Doesn't avoid shared single words\n",
    "        across train and test sets!!\n",
    "    \"\"\"\n",
    "    train_percent = 1 - val_percent\n",
    "    \n",
    "    n = df.shape[0]\n",
    "    idxs = np.arange(n)\n",
    "    np.random.seed(seed)\n",
    "    if shuffle: np.random.shuffle(idxs)\n",
    "    \n",
    "    train_idxs = idxs[:int(n*train_percent)]\n",
    "    val_idxs = idxs[int(n*train_percent):]\n",
    "    \n",
    "    return train_idxs, val_idxs\n",
    "\n",
    "\n",
    "def score_preds(df):\n",
    "    return pearsonr(df[df.in_vocab==True].mean_rating, \n",
    "                    df[df.in_vocab==True].preds)\n",
    "\n",
    "\n",
    "def get_rel_sim_preds(df, model, dims=None,\n",
    "                      metric='e'):\n",
    "    \n",
    "    preds, in_vocab = [], []\n",
    "    for r, row in df.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "        \n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "            \n",
    "            sim = compute_similarity(diff_pair1, diff_pair2,\n",
    "                                     metric=metric)\n",
    "            preds.append(sim)\n",
    "            in_vocab.append(True)\n",
    "        else:\n",
    "            preds.append(999)\n",
    "            in_vocab.append(False)\n",
    "        \n",
    "    df['preds'] = preds\n",
    "    df['in_vocab'] = in_vocab\n",
    "    return df\n",
    "\n",
    "def search_for_best_axes(df, model, epsilon=0, verbose=0):\n",
    "    \"\"\" Find the subset of dimensions (axis-aligned subspace)\n",
    "        giving the best fit to human data.\n",
    "    \"\"\"\n",
    "    \n",
    "    n_feats = model['dog'].size\n",
    "    feat_idx_keep = np.arange(n_feats)\n",
    "    \n",
    "    df_pred = get_rel_sim_preds(df, model)\n",
    "    base_score = score_preds(df_pred)[0]\n",
    "    best_score = base_score\n",
    "    if verbose > 0:\n",
    "        print('Base Score : %.4f, Features: %i' % (best_score, n_feats))\n",
    "    \n",
    "    for feat_idx in np.arange(n_feats):\n",
    "        \n",
    "        curr_feat_set_proposal = feat_idx_keep[feat_idx_keep!=feat_idx]\n",
    "\n",
    "        df_pred = get_rel_sim_preds(df, model, dims=curr_feat_set_proposal)\n",
    "        curr_score = score_preds(df_pred)[0]\n",
    "        \n",
    "        if (curr_score > best_score) and (curr_score-best_score > epsilon):\n",
    "            best_score = curr_score\n",
    "            feat_idx_keep = curr_feat_set_proposal\n",
    "            if verbose > 1:\n",
    "                print('-- New Best: %.4f, Features: %i' % (best_score, feat_idx_keep.size))\n",
    "                \n",
    "    if verbose > 0:                \n",
    "        print('Final Score: %.4f, Features: %i' % (best_score, feat_idx_keep.size))\n",
    "            \n",
    "    return feat_idx_keep, base_score, best_score\n",
    "\n",
    "# def apply_func_to_all_models(models, func, subset=None):\n",
    "    \n",
    "#     if subset is not None: \n",
    "#         model_list = models.keys()\n",
    "#     else:\n",
    "#         model_list = subset\n",
    "    \n",
    "#     results = {}\n",
    "#     for model_key in model_list:\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading asymmetry data in relsim style.\n",
      "Use mode='orig' for the standard format.\n"
     ]
    }
   ],
   "source": [
    "# load human relational similarity data\n",
    "df_rel_sim = load_relsim_data()\n",
    "\n",
    "# load human directional (asymmetric) \n",
    "# relational similarity data\n",
    "df_asym = load_asym_data()\n",
    "\n",
    "# get the vocab for each dataset\n",
    "vocab_rel_sim = get_relsim_vocab(df_rel_sim)\n",
    "vocab_asym = get_relsim_vocab(df_asym)\n",
    "\n",
    "# merge vocabs, easier for the future\n",
    "vocab_all = vocab_rel_sim + vocab_asym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No condensed models found. Creating now...\n",
      "No condensed models found. Creating now...\n",
      "No condensed models found. Creating now...\n",
      "No condensed models found. Creating now...\n",
      "No condensed models found. Creating now...\n"
     ]
    }
   ],
   "source": [
    "# where to find vector space models\n",
    "data_pth = '../../../../datasets/word-vector-datasets/'\n",
    "folders = ['glove','w2v']\n",
    "\n",
    "# load meta for all models\n",
    "models_meta = get_fns_and_meta(data_pth, folders)\n",
    "\n",
    "# store all condensed models in one dict\n",
    "# models = makesave_or_load_condensed(models_meta)\n",
    "makesave_or_load_condensed(models_meta, vocab_all, \n",
    "    load_condensed_stem='relsim.asym.condensed.p')\n",
    "\n",
    "# # quick pointers to a few important models\n",
    "# w2v_gnews = models['GoogleNews-vectors-negative300']['model']\n",
    "# glove = models['glove.840B.300d']['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list = models.keys()\n",
    "model_list = ['GoogleNews-vectors-negative300',\n",
    "              'glove.840B.300d']\n",
    "\n",
    "# basic analysis\n",
    "for model_key in model_list:\n",
    "    model = models[model_key]['model']\n",
    "    df_rel_sim = get_rel_sim_preds(df_rel_sim, model)\n",
    "    print(model_key, \n",
    "          score_preds(df_rel_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "for m, model_key in enumerate(model_list):\n",
    "    model = models[model_key]['model']\n",
    "    print(model_key)\n",
    "    search_for_best_axes(df_rel_sim, model, epsilon=0.0001, verbose=1)\n",
    "    if (m+1) < len(model_list): print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "n_splits = 10\n",
    "epsilon = 0.0001\n",
    "\n",
    "all_base_scores = []\n",
    "all_best_scores = []\n",
    "\n",
    "train_base_scores = []\n",
    "train_best_scores = []\n",
    "\n",
    "val_base_scores = []\n",
    "val_best_scores = []\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "\n",
    "    feats_all_data, all_base_score, all_best_score = \\\n",
    "        search_for_best_axes(df_exp, model, verbose=1, epsilon=epsilon)\n",
    "    all_base_scores.append(all_base_score)\n",
    "    all_best_scores.append(all_best_score)\n",
    "    print('')\n",
    "    \n",
    "    avg_train_base_scores = []\n",
    "    avg_train_best_scores = []\n",
    "    avg_val_base_scores = []\n",
    "    avg_val_best_scores = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        train_idxs, val_idxs = naive_train_val_split(df_exp, \n",
    "                                                      val_percent=0.2, \n",
    "                                                      shuffle=True)\n",
    "\n",
    "    #     print('Type', rel_type, ' - Training Score', \n",
    "    #           df_exp.iloc[train_idxs].shape[0])\n",
    "\n",
    "        feats_train, train_base_score, train_best_score = \\\n",
    "            search_for_best_axes(df_exp.iloc[train_idxs].copy(), \n",
    "                                 model, verbose=0, epsilon=epsilon)\n",
    "        \n",
    "        df_val_base = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model)\n",
    "        df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model, dims=feats_train)\n",
    "        print(score_preds(df_val)[0])\n",
    "        \n",
    "        avg_train_base_scores.append(train_base_score)\n",
    "        avg_train_best_scores.append(train_best_score)\n",
    "        avg_val_base_scores.append(score_preds(df_val_base)[0])\n",
    "        avg_val_best_scores.append(score_preds(df_val)[0])\n",
    "        \n",
    "    print('mean val', np.mean(avg_val_best_scores))\n",
    "    \n",
    "    train_base_scores.append(np.mean(avg_train_base_scores))\n",
    "    train_best_scores.append(np.mean(avg_train_best_scores))\n",
    "    val_base_scores.append(np.mean(avg_val_base_scores))\n",
    "    val_best_scores.append(np.mean(avg_val_best_scores))\n",
    "#     print('')\n",
    "    \n",
    "#     df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), model, dims=feats_train)\n",
    "\n",
    "#     print('Type', rel_type, ' - Validation Score', \n",
    "#           df_exp.iloc[val_idxs].shape[0])\n",
    "#     print('%.4f' % score_preds(df_val)[0])\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JOBLIB TEST!!! ###\n",
    "\n",
    "# search for a subset of dimensions with best\n",
    "# overall score across all types/subtypes\n",
    "\n",
    "condensed_model = create_condensed_model(df_rel_sim, model)\n",
    "\n",
    "n_splits = 50\n",
    "epsilon = 0.0001\n",
    "\n",
    "all_base_scores = []\n",
    "all_best_scores = []\n",
    "\n",
    "train_base_scores = []\n",
    "train_best_scores = []\n",
    "\n",
    "val_base_scores = []\n",
    "val_best_scores = []\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "\n",
    "    feats_all_data, all_base_score, all_best_score = \\\n",
    "        search_for_best_axes(df_exp, model, verbose=0, epsilon=epsilon)\n",
    "    all_base_scores.append(all_base_score)\n",
    "    all_best_scores.append(all_best_score)\n",
    "#     print('')\n",
    "    \n",
    "    avg_train_base_scores = []\n",
    "    avg_train_best_scores = []\n",
    "    avg_val_base_scores = []\n",
    "    avg_val_best_scores = []\n",
    "    \n",
    "    def run_split(seed, df_exp):\n",
    "        train_idxs, val_idxs = naive_train_val_split(df_exp, \n",
    "                                                      val_percent=0.2,\n",
    "                                                      shuffle=True,\n",
    "                                                      seed=seed)\n",
    "\n",
    "        feats_train, train_base_score, train_best_score = \\\n",
    "            search_for_best_axes(df_exp.iloc[train_idxs].copy(), \n",
    "                                 condensed_model, verbose=0, epsilon=epsilon)\n",
    "        \n",
    "        df_val_base = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), condensed_model)\n",
    "        val_base_score = score_preds(df_val_base)[0]\n",
    "        \n",
    "        df_val = get_rel_sim_preds(df_exp.iloc[val_idxs].copy(), condensed_model, dims=feats_train)\n",
    "        val_best_score = score_preds(df_val)[0]\n",
    "        \n",
    "        return train_base_score, train_best_score, val_base_score, val_best_score\n",
    "    \n",
    "    results = Parallel(n_jobs=n_splits)(delayed(run_split)(i, df_exp) for i in range(n_splits))\n",
    "    for result in results: print(result)\n",
    "    \n",
    "    for result in results:        \n",
    "        avg_train_base_scores.append(result[0])\n",
    "        avg_train_best_scores.append(result[1])\n",
    "        avg_val_base_scores.append(result[2])\n",
    "        avg_val_best_scores.append(result[3])\n",
    "        \n",
    "    print('mean val', np.mean(avg_val_best_scores))\n",
    "    \n",
    "    train_base_scores.append(np.mean(avg_train_base_scores))\n",
    "    train_best_scores.append(np.mean(avg_train_best_scores))\n",
    "    val_base_scores.append(np.mean(avg_val_base_scores))\n",
    "    val_best_scores.append(np.mean(avg_val_best_scores))\n",
    "\n",
    "    print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type 1 epsilon test\n",
    "# 121 0       0.5298 0.4289\n",
    "# 121 0.00001 0.5298 0.4127\n",
    "# 127 0.0001  0.5230 0.4552\n",
    "# 204 0.001   0.4023 0.3364\n",
    "# 300 0.01    0.1511 NA\n",
    "# 300 0.1     0.1511 NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rel_type in range(1, 11):\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    print('Type', rel_type, ' - All Data Score', df_exp.shape[0])\n",
    "    df_exp = get_rel_sim_preds(df_exp, model, metric='e')\n",
    "\n",
    "    print(score_preds(df_exp)[0])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=150)\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "bars1 = all_base_scores\n",
    "bars2 = all_best_scores\n",
    "bars3 = val_best_scores\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(bars1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, bars1, color='black', width=barWidth, edgecolor='white', \n",
    "        label='Original GloVe')\n",
    "plt.axhline(y=np.mean(bars1), color='black', linestyle='--')\n",
    "plt.bar(r2, bars2, color='#2d7f5e', width=barWidth, edgecolor='white', \n",
    "        label='Best Subspace (All Data)')\n",
    "plt.axhline(y=np.mean(bars2), color='#2d7f5e', linestyle='--')\n",
    "plt.bar(r3, bars3, color='purple', width=barWidth, edgecolor='white', \n",
    "        label='Best Subspace (Mean 10x Validation)')\n",
    "plt.axhline(y=np.mean(bars3), color='purple', linestyle='--')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "# plt.xlabel('group', fontweight='bold')\n",
    "plt.ylabel('Pearson $r$', fontweight='bold')\n",
    "plt.xlabel('Relation Type', fontweight='bold')\n",
    "plt.xticks([r + barWidth for r in range(len(bars1))], range(1, 11))\n",
    "\n",
    "plt.ylim([0,1])\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_params = (df_rel_sim.rel1_type==2) & (df_rel_sim.rel2_type==2)\n",
    "\n",
    "df_rel_sim[exp_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,15))\n",
    "# fig, ax = plt.subplots(2, 5)\n",
    "# ax = ax.flatten()\n",
    "\n",
    "for rel_type in range(1, 11):\n",
    "    plt.figure()\n",
    "    \n",
    "    # within-TYPE trials only (what Dawn did for paper!)\n",
    "    exp_params = (df_rel_sim.rel1_type==rel_type) & (df_rel_sim.rel2_type==rel_type)\n",
    "    \n",
    "    df_exp = df_rel_sim[exp_params].copy()\n",
    "    \n",
    "    result = search_for_best_axes(df_exp, model, \n",
    "                                  epsilon=0.0001, verbose=0)\n",
    "    good_feats = result[0]\n",
    "    \n",
    "    for r, row in df_exp.iterrows():\n",
    "\n",
    "        words = get_analogy_words(row)\n",
    "\n",
    "        if words_in_vocab(words, model):\n",
    "\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model)\n",
    "\n",
    "            sim = compute_similarity(diff_pair1[good_feats], \n",
    "                                     diff_pair2[good_feats],\n",
    "                                     metric='e')\n",
    "        plt.scatter(row.mean_rating, -sim, \n",
    "                    s=10, color='blue', alpha=0.5)\n",
    "#         ax[rel_type-1].scatter(row.mean_rating, -sim, \n",
    "#                     s=10, color='blue', alpha=0.5)\n",
    "    print(rel_type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_rel_sim.copy()\n",
    "\n",
    "# train_idxs, val_idxs = naive_train_val_split(df)\n",
    "\n",
    "# train_raw = df.iloc[train_idxs].copy()\n",
    "# val_raw = df.iloc[val_idxs].copy()\n",
    "\n",
    "\n",
    "\n",
    "# val_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_rel_sim, columns=['comparison_type'])[['comparison_type_between-subtype', \n",
    "                                                        'comparison_type_between-type',\n",
    "                                                        'comparison_type_within-subtype']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_exp = df_rel_sim.copy() # all data\n",
    "df_exp = df_rel_sim[df_rel_sim.comparison_type!='between-type'].copy()\n",
    "\n",
    "train_idxs, val_idxs = naive_train_val_split(df_exp, seed=3)\n",
    "\n",
    "def build_data_for_tuning(df, model, train_idxs, val_idxs, dims=None):\n",
    "    \n",
    "    train_raw = df.iloc[train_idxs].copy()\n",
    "    val_raw = df.iloc[val_idxs].copy()\n",
    "    \n",
    "    U_train, U_val = [], []\n",
    "    V_train, V_val = [], []\n",
    "    y_train, y_val = [], []\n",
    "#     type_train = [], type_val = [], []\n",
    "    \n",
    "    for r, row in train_raw.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "        \n",
    "        U_train.append(diff_pair1)\n",
    "        V_train.append(diff_pair2)\n",
    "        y_train.append(row.mean_rating)\n",
    "        \n",
    "    for r, row in val_raw.iterrows():\n",
    "        \n",
    "        words = get_analogy_words(row)\n",
    "        \n",
    "        if words_in_vocab(words, model):\n",
    "            diff_pair1, diff_pair2 = \\\n",
    "                get_diff_vecs(words, model, dims=dims)\n",
    "            \n",
    "        U_val.append(diff_pair1)\n",
    "        V_val.append(diff_pair2)\n",
    "        y_val.append(row.mean_rating)\n",
    "        \n",
    "    return [np.array(x) for x in [U_train, U_val, V_train, V_val, y_train, y_val]]\n",
    "\n",
    "# create dataset\n",
    "U_train, U_val, V_train, V_val, y_train, y_val = \\\n",
    "    build_data_for_tuning(df_exp,\n",
    "                          w2v_gnews, train_idxs, val_idxs)\n",
    "\n",
    "# check shapes\n",
    "for _ in [U_train, U_val, V_train, V_val, y_train, y_val]:\n",
    "    print(_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for u, v in zip(U_val, V_val):\n",
    "    pred = compute_similarity(u, v, metric='e')\n",
    "    preds.append(pred)\n",
    "    \n",
    "print(np.corrcoef(preds, y_val)[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import concatenate, multiply, dot\n",
    "from keras.models import Model\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='linear')(diff_vecs)\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(60):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALLOW NEGATIVE WEIGHTS!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='linear')(diff_vecs)\n",
    "#w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHARED WEIGHTS!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "shared = Dense(d, activation='linear')\n",
    "\n",
    "u_w = shared(u_input)\n",
    "v_w = shared(v_input)\n",
    "\n",
    "w = keras.layers.add([u_w, v_w])\n",
    "\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHARED WEIGHTS + WEIGHT REGULARIZATION!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "shared = Dense(d, activation='linear',\n",
    "               kernel_regularizer=keras.regularizers.l2(0.0001))\n",
    "\n",
    "u_w = shared(u_input)\n",
    "v_w = shared(v_input)\n",
    "\n",
    "w = keras.layers.add([u_w, v_w])\n",
    "\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(200):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RELU INSTEAD OF SQUARE W!!\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "w = Dense(d, activation='relu')(diff_vecs)\n",
    "\n",
    "u_mult_w = multiply([u_input, w])\n",
    "\n",
    "final_dot = dot([u_mult_w, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(60):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRY BOTTLENECK!!\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import concatenate, multiply, dot\n",
    "from keras.models import Model\n",
    "\n",
    "d = 300\n",
    "\n",
    "u_input = Input(shape=(d,))\n",
    "v_input = Input(shape=(d,))\n",
    "\n",
    "diff_vecs = concatenate([u_input, v_input])\n",
    "\n",
    "bottleneck = Dense(150, activation='linear')(diff_vecs)\n",
    "w = Dense(d, activation='linear')(bottleneck)\n",
    "w_sq = multiply([w, w])\n",
    "\n",
    "u_mult_w_sq = multiply([u_input, w_sq])\n",
    "\n",
    "final_dot = dot([u_mult_w_sq, v_input], axes=1)\n",
    "\n",
    "tuner = Model(inputs=[u_input, v_input], \n",
    "              outputs=final_dot)\n",
    "\n",
    "# print(tuner.summary())\n",
    "\n",
    "tuner.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error')\n",
    "\n",
    "def eval_tuner():\n",
    "    preds_train = tuner.predict([U_train, V_train])\n",
    "    preds_val = tuner.predict([U_val, V_val])\n",
    "    print('Train:', np.corrcoef(preds_train.flatten(), y_train)[0,1])\n",
    "    print('Val  :', np.corrcoef(preds_val.flatten(), y_val)[0,1])\n",
    "    print('')\n",
    "\n",
    "eval_tuner()\n",
    "for epoch in range(50):\n",
    "    tuner.fit([U_train, V_train], y_train, \n",
    "              validation_data=([U_val, V_val], y_val),\n",
    "              verbose=1)\n",
    "    eval_tuner()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
